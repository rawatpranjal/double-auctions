{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b60ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action Space Type</th>\n",
       "      <th>Key Innovation</th>\n",
       "      <th>On - Off Policy</th>\n",
       "      <th>Value / Policy Based</th>\n",
       "      <th>Year of Publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REINFORCE</th>\n",
       "      <td>Both</td>\n",
       "      <td>Direct policy optimization with policy gradien...</td>\n",
       "      <td>On</td>\n",
       "      <td>Policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRPO</th>\n",
       "      <td>Both</td>\n",
       "      <td>Trust region optimization for stable learning....</td>\n",
       "      <td>On</td>\n",
       "      <td>Policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPO</th>\n",
       "      <td>Both</td>\n",
       "      <td>Clipped surrogate objective for stable learnin...</td>\n",
       "      <td>On</td>\n",
       "      <td>Policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2C</th>\n",
       "      <td>Both</td>\n",
       "      <td>Combines actor and critic for efficient traini...</td>\n",
       "      <td>On</td>\n",
       "      <td>Both</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DQN</th>\n",
       "      <td>Discrete</td>\n",
       "      <td>Deep Q-network approximation of the Q-function...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Value</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDPG</th>\n",
       "      <td>Continuous</td>\n",
       "      <td>Continuous action space extension of DQN. Adap...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Both</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3C</th>\n",
       "      <td>Both</td>\n",
       "      <td>Asynchronous training of multiple agents. Para...</td>\n",
       "      <td>On</td>\n",
       "      <td>Both</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAC</th>\n",
       "      <td>Continuous</td>\n",
       "      <td>Entropy regularization for improved exploratio...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Both</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD3</th>\n",
       "      <td>Both</td>\n",
       "      <td>Twin critics and delayed policy updates. Intro...</td>\n",
       "      <td>On</td>\n",
       "      <td>Both</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4PG</th>\n",
       "      <td>Continuous</td>\n",
       "      <td>Distributional value estimation with determini...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Both</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-Learning</th>\n",
       "      <td>Discrete</td>\n",
       "      <td>Value iteration with Q-value updates. Introduc...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Value</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Action Space Type  \\\n",
       "REINFORCE               Both   \n",
       "TRPO                    Both   \n",
       "PPO                     Both   \n",
       "A2C                     Both   \n",
       "DQN                 Discrete   \n",
       "DDPG              Continuous   \n",
       "A3C                     Both   \n",
       "SAC               Continuous   \n",
       "TD3                     Both   \n",
       "D4PG              Continuous   \n",
       "Q-Learning          Discrete   \n",
       "\n",
       "                                               Key Innovation On - Off Policy  \\\n",
       "REINFORCE   Direct policy optimization with policy gradien...              On   \n",
       "TRPO        Trust region optimization for stable learning....              On   \n",
       "PPO         Clipped surrogate objective for stable learnin...              On   \n",
       "A2C         Combines actor and critic for efficient traini...              On   \n",
       "DQN         Deep Q-network approximation of the Q-function...             Off   \n",
       "DDPG        Continuous action space extension of DQN. Adap...             Off   \n",
       "A3C         Asynchronous training of multiple agents. Para...              On   \n",
       "SAC         Entropy regularization for improved exploratio...             Off   \n",
       "TD3         Twin critics and delayed policy updates. Intro...              On   \n",
       "D4PG        Distributional value estimation with determini...             Off   \n",
       "Q-Learning  Value iteration with Q-value updates. Introduc...             Off   \n",
       "\n",
       "           Value / Policy Based Year of Publication  \n",
       "REINFORCE                Policy                None  \n",
       "TRPO                     Policy                None  \n",
       "PPO                      Policy                None  \n",
       "A2C                        Both                None  \n",
       "DQN                       Value                2015  \n",
       "DDPG                       Both                2016  \n",
       "A3C                        Both                2016  \n",
       "SAC                        Both                2018  \n",
       "TD3                        Both                2018  \n",
       "D4PG                       Both                2018  \n",
       "Q-Learning                Value                1957  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Action Space Type\": [\"Both\", \"Both\", \"Both\", \"Both\", \"Discrete\", \"Continuous\", \"Both\", \"Continuous\", \"Both\", \"Continuous\", \"Discrete\"],\n",
    "    \"Key Innovation\": [\n",
    "        \"Direct policy optimization with policy gradient. Introduced the idea of optimizing the policy directly using gradient ascent. Enabled learning in high-dimensional action spaces.\",\n",
    "        \"Trust region optimization for stable learning. Introduced trust region methods to stabilize policy updates and prevent large policy changes that could lead to divergence.\",\n",
    "        \"Clipped surrogate objective for stable learning. Addressed issues with trust region methods by using a clipped surrogate objective, ensuring monotonic improvement.\",\n",
    "        \"Combines actor and critic for efficient training. Utilizes both value and policy networks to improve sample efficiency and convergence speed.\",\n",
    "        \"Deep Q-network approximation of the Q-function. Introduced deep neural networks to approximate the Q-function, making it possible to handle high-dimensional state spaces.\",\n",
    "        \"Continuous action space extension of DQN. Adapted DQN for continuous action spaces using actor-critic architecture and deterministic policy gradients.\",\n",
    "        \"Asynchronous training of multiple agents. Parallelizes training by having multiple agents interact with their environments asynchronously, improving data efficiency.\",\n",
    "        \"Entropy regularization for improved exploration. Encourages exploration by adding an entropy term to the objective function, balancing exploration and exploitation.\",\n",
    "        \"Twin critics and delayed policy updates. Introduced twin Q-networks to improve stability and utilized delayed policy updates for better performance.\",\n",
    "        \"Distributional value estimation with deterministic policy gradients. Estimated value distributions instead of single values and combined them with deterministic policy gradients for improved learning.\",\n",
    "        \"Value iteration with Q-value updates. Introduced the concept of Q-values and iteratively updates Q-values using the Bellman equation for value estimation.\"\n",
    "    ],\n",
    "    \"On - Off Policy\": [\"On\", \"On\", \"On\", \"On\", \"Off\", \"Off\", \"On\", \"Off\", \"On\", \"Off\", \"Off\"],\n",
    "    \"Value / Policy Based\": [\"Policy\", \"Policy\", \"Policy\", \"Both\", \"Value\", \"Both\", \"Both\", \"Both\", \"Both\", \"Both\", \"Value\"],\n",
    "    \"Year of Publication\": [None, None, None, None, \"2015\", \"2016\", \"2016\", \"2018\", \"2018\", \"2018\", \"1957\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=[\"REINFORCE\", \"TRPO\", \"PPO\", \"A2C\", \"DQN\", \"DDPG\", \"A3C\", \"SAC\", \"TD3\", \"D4PG\", \"Q-Learning\"])\n",
    "\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399868c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from functions import *\n",
    "from itertools import count\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO, A2C, DQN, SAC\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce0ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Setup\n",
    "buyer_strategies = ['Honest', 'Random', 'Random', 'Random','Random']\n",
    "seller_strategies = ['Random', 'Random', 'Random', 'Random', 'Random','Random', 'Random', 'Random', 'Random', 'Random']\n",
    "nbuyers, nsellers = len(buyer_strategies), len(seller_strategies)\n",
    "nrounds, nperiods, ntokens, nsteps, gametype, nbuyers, nsellers = 2, 2, 10, 50, '1234', len(buyer_strategies), len(seller_strategies)\n",
    "R1, R2, R3, R4 = gametype_to_ran(gametype)\n",
    "game_metadata = [nrounds, nperiods, ntokens, nbuyers, nsellers, nsteps, R1, R2, R3, R4]\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "rnd = 0\n",
    "period = 0\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "num_actions = 51 # discrete\n",
    "num_states = nsteps\n",
    "min_frac = 0.01\n",
    "max_frac = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87aeeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, db, nsteps, render_mode = None):\n",
    "        self.rnd = 0\n",
    "        self.period = -1\n",
    "        self.nperiods = nperiods\n",
    "        self.db = db\n",
    "        self.action_space = spaces.Box(0,1,(1,),dtype=np.float)\n",
    "        self.observation_space = spaces.Box(-1,200,(13,),dtype=np.float32)\n",
    "\n",
    "    def reset(self,seed=None):\n",
    "        #self.db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "        self.db.reset_period(self.rnd)\n",
    "        self.timestep = 0\n",
    "        self.period += 1\n",
    "        self.db.buyers[0].next_token()\n",
    "        agent = self.db.buyers[0]\n",
    "        observation = np.array([0,-1,-1,-1,-1,-1,-1,-1,agent.value,-1,-1,-1,agent.num_tokens_traded], dtype = np.float32)\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action, seed=None, options=None):\n",
    "        [buyer.next_token() for buyer in self.db.buyers]\n",
    "        [seller.next_token() for seller in self.db.sellers]\n",
    "        bid_frac = action.item()\n",
    "        # convert action to bid\n",
    "        self.db.buyers[0].next_token()\n",
    "        min_bid = self.db.buyers[0].value * min_frac\n",
    "        max_bid = self.db.buyers[0].value * max_frac\n",
    "        bid = np.round(max_bid * bid_frac + (1 - bid_frac) * min_bid, 2)\n",
    "\n",
    "        # simulate market\n",
    "        bids = [buyer.bid(self.db) for buyer in self.db.buyers]\n",
    "        bids[0] = bid\n",
    "        asks = [seller.ask(self.db) for seller in self.db.sellers]\n",
    "        current_ask, current_ask_idx, current_bid, current_bid_idx = current_bid_ask(bids, asks)\n",
    "        sale, price, bprofit, sprofit, buy, sell = buy_sell(self.db, current_bid, current_bid_idx, current_ask, current_ask_idx)\n",
    "        step_data = [self.rnd, self.period, self.timestep, bids, asks, current_bid, current_bid_idx, current_ask, current_ask_idx, buy, sell, price, sale, bprofit, sprofit]\n",
    "        self.db.add_step(step_data)\n",
    "\n",
    "        # compute reward, new state\n",
    "        reward = 0.0\n",
    "        if sale == 1 and current_bid_idx == 0:\n",
    "            reward = bprofit\n",
    "            \n",
    "        agent = self.db.buyers[0]\n",
    "        observation = np.array([self.timestep + 1, current_ask, current_ask_idx, current_bid, current_bid_idx,\n",
    "                                sale, price, buy, sell, agent.value, agent.step_profit,\n",
    "                                agent.sale, agent.num_tokens_traded],dtype = np.float32)\n",
    "        idx = np.isnan(observation)\n",
    "        observation[idx] = -1.0\n",
    "        # check termination\n",
    "        self.timestep += 1\n",
    "        if self.timestep == nsteps:\n",
    "            terminated = True\n",
    "            self.timestep = 0\n",
    "        else:\n",
    "            terminated = False\n",
    "        infos = {\"TimeLimit.truncated\":True}\n",
    "        truncated = False\n",
    "        return observation, reward, terminated, truncated, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313e5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d7618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnd: 0, Period: 0, New State: [ 1.  17.4  9.  81.   1.   1.  49.2  1.   1.  72.5  0.   1.   0. ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 2.  17.8  0.  89.2  4.   1.  53.5  1.   1.  72.5  0.   1.   0. ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 3.   18.3   6.   80.6   1.    1.   49.45  1.    1.   72.5   0.    1.\n",
      "  0.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 4.   21.    1.   83.3   3.    1.   52.15  1.    1.   72.5   0.    1.\n",
      "  0.  ], Action:[0.6], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 5.    17.3    8.    78.33   0.     1.    47.815  1.     1.    72.5\n",
      " 24.685  1.     1.   ], Action:[0.7], Reward: 24.7, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 6.    24.6    7.    68.     3.     1.    46.3    1.     1.    64.1\n",
      " 24.685  1.     1.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 7.    26.4    7.    72.6    1.     1.    49.5    1.     1.    64.1\n",
      " 24.685  1.     1.   ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 8.    25.7    1.    83.89   0.     1.    54.795  1.     1.    64.1\n",
      "  9.305  1.     2.   ], Action:[0.9], Reward: 9.3, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 9.    23.4    4.    75.     4.     1.    49.2    1.     1.    61.7\n",
      "  9.305  1.     2.   ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [10.    30.     1.    79.1    1.     1.    54.55   1.     1.    61.7\n",
      "  9.305  1.     2.   ], Action:[0.6], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [11.    29.8    1.    67.8    4.     1.    48.8    1.     1.    61.7\n",
      "  9.305  1.     2.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [12.    29.3    8.    78.     1.     1.    53.65   1.     1.    61.7\n",
      "  9.305  1.     2.   ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [13.    30.9    1.    49.6    2.     1.    40.25   1.     1.    61.7\n",
      "  9.305  1.     2.   ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [14.    33.4    3.    83.1    2.     1.    58.25   1.     1.    61.7\n",
      "  9.305  1.     2.   ], Action:[0.6], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [15.    28.5    4.    65.5    3.     1.    47.     1.     1.    61.7\n",
      "  9.305  1.     2.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [16.    31.1    2.    58.53   0.     1.    44.815  1.     1.    61.7\n",
      " 16.885  1.     3.   ], Action:[0.6], Reward: 16.9, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [17.    29.3    5.    68.93   0.     1.    49.115  1.     1.    59.5\n",
      " 10.385  1.     4.   ], Action:[0.8], Reward: 10.4, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [18.    31.2    2.    70.1    1.     1.    50.65   1.     1.    49.9\n",
      " 10.385  1.     4.   ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [19.    35.1    5.    52.     3.     1.    43.55   1.     1.    49.9\n",
      " 10.385  1.     4.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [20.   41.1   8.   61.02  0.    1.   51.06  1.    1.   49.9  -1.16  1.\n",
      "  5.  ], Action:[0.8], Reward: -1.2, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [21.   45.3   0.   71.3   1.    1.   58.3   1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [22.   43.1   3.   55.1   4.    1.   49.1   1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [23.   39.3   6.   52.3   4.    1.   45.8   1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [24.   42.2   3.   61.    3.    1.   51.6   1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [25.   41.7   7.   60.3   3.    1.   51.    1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [26.   49.6   3.   59.9   2.    1.   54.75  1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [27.   43.6   6.   62.    1.    1.   52.8   1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [28.   46.    0.   57.3   1.    1.   51.65  1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.6], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [29.   41.5   4.   45.5   4.    1.   43.5   1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.6], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [30.   40.1   8.   42.5   2.    1.   41.3   1.    1.   44.8  -1.16  1.\n",
      "  5.  ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [31.   47.    3.   53.56  0.    1.   53.56  0.    1.   44.8  -8.76  0.\n",
      "  6.  ], Action:[0.8], Reward: -8.8, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [32.   47.7   3.   55.5   3.    1.   51.6   1.    1.   36.1  -8.76  0.\n",
      "  6.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [33.   46.8   7.   42.2   3.    1.   46.8   1.    0.   36.1  -8.76  0.\n",
      "  6.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [34.   47.3   6.   38.9   4.    0.   -1.    0.    0.   36.1  -8.76  0.\n",
      "  6.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 35.    50.4    9.    52.76   0.     1.    52.76   0.     1.    36.1\n",
      " -16.66   0.     7.  ], Action:[1.], Reward: -16.7, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 36.    49.3    6.    27.4    2.     1.    49.3    1.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 37.    53.6    4.    43.     3.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 38.    51.2    5.    48.2    3.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 39.    49.4    2.    47.     3.     1.    48.2    1.     1.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 40.    58.6    5.    33.5    4.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 41.    51.9    5.    31.1    4.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 42.    54.2    0.    32.11   0.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 43.    49.6    3.    39.6    3.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 44.    49.1    5.    35.48   0.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 45.    46.6    2.    39.5    3.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 46.    51.5    9.    26.5    2.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 47.    46.7    2.    34.4    4.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 48.    50.3    9.    40.     4.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 49.    49.4    3.    32.7    3.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 0, New State: [ 50.    47.7    9.    37.01   0.     0.    -1.     0.     0.    25.7\n",
      " -16.66   0.     7.  ], Action:[1.], Reward: 0.0, Period End: True\n",
      "Rnd: 0, Period: 1, New State: [  1.   17.6   9.  108.4   0.    1.   63.    1.    1.   72.5   9.5   1.\n",
      "   1. ], Action:[1.], Reward: 9.5, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 2.  19.9  8.  82.5  4.   1.  51.2  1.   1.  64.1  9.5  1.   1. ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 3.   19.8   6.   63.7   2.    1.   41.75  1.    1.   64.1   9.5   1.\n",
      "  1.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 4.  18.3  0.  63.5  3.   1.  40.9  1.   1.  64.1  9.5  1.   1. ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 5.   26.2   1.   62.3   1.    1.   44.25  1.    1.   64.1   9.5   1.\n",
      "  1.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 6.    24.9    4.    73.87   0.     1.    49.385  1.     1.    64.1\n",
      " 14.715  1.     2.   ], Action:[0.8], Reward: 14.7, Period End: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnd: 0, Period: 1, New State: [ 7.    22.     7.    75.9    2.     1.    48.95   1.     1.    61.7\n",
      " 14.715  1.     2.   ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 8.    25.     8.    77.6    1.     1.    51.3    1.     1.    61.7\n",
      " 14.715  1.     2.   ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 9.    27.2    7.    83.4    1.     1.    55.3    1.     1.    61.7\n",
      " 14.715  1.     2.   ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [10.    25.     1.    72.     1.     1.    48.5    1.     1.    61.7\n",
      " 14.715  1.     2.   ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [11.    25.6    1.    68.6    1.     1.    47.1    1.     1.    61.7\n",
      " 14.715  1.     2.   ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [12.    29.4    4.    75.7    4.     1.    52.55   1.     1.    61.7\n",
      " 14.715  1.     2.   ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [13.   35.2   5.   69.22  0.    1.   52.21  1.    1.   61.7   9.49  1.\n",
      "  3.  ], Action:[0.7], Reward: 9.5, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [14.   32.9   3.   69.1   3.    1.   51.    1.    1.   59.5   9.49  1.\n",
      "  3.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [15.   34.2   1.   63.9   2.    1.   49.05  1.    1.   59.5   9.49  1.\n",
      "  3.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [16.    39.1    8.    65.37   0.     1.    52.235  1.     1.    59.5\n",
      "  7.265  1.     4.   ], Action:[0.7], Reward: 7.3, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [17.    35.4    1.    72.6    1.     1.    54.     1.     1.    49.9\n",
      "  7.265  1.     4.   ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [18.    30.2    2.    71.2    4.     1.    50.7    1.     1.    49.9\n",
      "  7.265  1.     4.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [19.    34.5    2.    47.8    3.     1.    41.15   1.     1.    49.9\n",
      "  7.265  1.     4.   ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [20.    42.1    6.    63.8    3.     1.    52.95   1.     1.    49.9\n",
      "  7.265  1.     4.   ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [21.    45.5    0.    60.5    3.     1.    53.     1.     1.    49.9\n",
      "  7.265  1.     4.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [22.    45.2    0.    75.5    1.     1.    60.35   1.     1.    49.9\n",
      "  7.265  1.     4.   ], Action:[1.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [23.    37.2    5.    67.2    1.     1.    52.2    1.     1.    49.9\n",
      "  7.265  1.     4.   ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [24.    40.1    8.    57.85   0.     1.    48.975  1.     1.    49.9\n",
      "  0.925  1.     5.   ], Action:[0.8], Reward: 0.9, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [25.    46.1    3.    53.8    3.     1.    49.95   1.     1.    44.8\n",
      "  0.925  1.     5.   ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 26.    45.8    4.    65.55   0.     1.    65.55   0.     1.    44.8\n",
      " -20.75   0.     6.  ], Action:[1.], Reward: -20.8, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 27.    45.7    2.    42.2    1.     1.    45.7    1.     0.    36.1\n",
      " -20.75   0.     6.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 28.    45.     6.    53.7    4.     1.    49.35   1.     1.    36.1\n",
      " -20.75   0.     6.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 29.    48.9    6.    50.34   0.     1.    50.34   0.     1.    36.1\n",
      " -14.24   0.     7.  ], Action:[0.9], Reward: -14.2, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 30.    46.7    3.    49.3    2.     1.    48.     1.     1.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 31.    47.3    2.    49.9    3.     1.    48.6    1.     1.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 32.    42.7    3.    54.1    3.     1.    48.4    1.     1.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 33.    44.5    7.    54.2    4.     1.    49.35   1.     1.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 34.    50.2    8.    44.9    4.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 35.    49.8    3.    40.1    2.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[1.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 36.    48.8    3.    35.3    2.     1.    48.8    1.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 37.    52.2    5.    32.4    2.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 38.    43.9    3.    34.8    4.     1.    43.9    1.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 39.    46.6    9.    39.1    4.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 40.    53.8    8.    37.7    4.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 41.    48.6    5.    45.5    3.     1.    48.6    1.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 42.    44.8    9.    39.     3.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 43.    46.5    7.    36.15   0.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 44.    49.4    8.    39.4    3.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 45.    51.2    7.    36.1    3.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.6], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 46.    45.7    9.    32.44   0.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 47.    48.5    4.    33.1    4.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 48.    50.9    7.    29.02   0.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 49.    49.1    9.    37.9    3.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 1, New State: [ 50.    48.1    4.    39.     3.     0.    -1.     0.     0.    25.7\n",
      " -14.24   0.     7.  ], Action:[1.], Reward: 0.0, Period End: True\n",
      "Rnd: 0, Period: 2, New State: [ 1.    17.     9.    76.87   0.     1.    46.935  1.     1.    72.5\n",
      " 25.565  1.     1.   ], Action:[0.7], Reward: 25.6, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 2.    17.7    6.    86.     1.     1.    51.85   1.     1.    64.1\n",
      " 25.565  1.     1.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 3.    21.3    7.    77.3    3.     1.    49.3    1.     1.    64.1\n",
      " 25.565  1.     1.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 4.    20.9    0.    69.     4.     1.    44.95   1.     1.    64.1\n",
      " 25.565  1.     1.   ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 5.    19.3    8.    63.1    1.     1.    41.2    1.     1.    64.1\n",
      " 25.565  1.     1.   ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 6.   28.8   1.   77.38  0.    1.   53.09  1.    1.   64.1  11.01  1.\n",
      "  2.  ], Action:[0.8], Reward: 11.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 7.   25.7   4.   91.54  0.    1.   58.62  1.    1.   61.7   3.08  1.\n",
      "  3.  ], Action:[1.], Reward: 3.1, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 8.   24.6   8.   76.1   4.    1.   50.35  1.    1.   59.5   3.08  1.\n",
      "  3.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 9.   27.3   1.   52.4   4.    1.   39.85  1.    1.   59.5   3.08  1.\n",
      "  3.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [10.   29.3   4.   71.5   1.    1.   50.4   1.    1.   59.5   3.08  1.\n",
      "  3.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [11.   25.4   1.   60.    2.    1.   42.7   1.    1.   59.5   3.08  1.\n",
      "  3.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [12.   29.7   7.   66.6   1.    1.   48.15  1.    1.   59.5   3.08  1.\n",
      "  3.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [13.   26.9   5.   72.    0.    1.   49.45  1.    1.   59.5  10.05  1.\n",
      "  4.  ], Action:[0.8], Reward: 10.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [14.   32.7   1.   74.34  0.    1.   53.52  1.    1.   49.9  -3.62  1.\n",
      "  5.  ], Action:[1.], Reward: -3.6, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [15.   32.9   3.   72.1   2.    1.   52.5   1.    1.   44.8  -3.62  1.\n",
      "  5.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [16.   32.4   2.   66.    1.    1.   49.2   1.    1.   44.8  -3.62  1.\n",
      "  5.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [17.   31.2   1.   58.2   3.    1.   44.7   1.    1.   44.8  -3.62  1.\n",
      "  5.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [18.   32.3   2.   54.74  0.    1.   43.52  1.    1.   44.8   1.28  1.\n",
      "  6.  ], Action:[0.8], Reward: 1.3, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [19.   36.    5.   72.3   1.    1.   54.15  1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [20.   37.5   8.   50.1   2.    1.   43.8   1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [21.   45.4   8.   72.3   3.    1.   58.85  1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.8], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [22.   41.5   6.   60.    3.    1.   50.75  1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [23.   42.4   7.   57.6   3.    1.   50.    1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [24.   39.2   0.   59.8   1.    1.   49.5   1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [25.   39.9   6.   44.8   2.    1.   42.35  1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [26.   41.2   0.   59.3   1.    1.   50.25  1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [27.   41.5   4.   55.7   4.    1.   48.6   1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [28.   48.5   7.   60.5   1.    1.   54.5   1.    1.   36.1   1.28  1.\n",
      "  6.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 29.    45.     3.    52.47   0.     1.    52.47   0.     1.    36.1\n",
      " -16.37   0.     7.  ], Action:[1.], Reward: -16.4, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 30.    46.3    6.    54.9    3.     1.    50.6    1.     1.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 31.    41.5    3.    38.5    2.     1.    41.5    1.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[1.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 32.    50.7    8.    41.3    4.     1.    50.7    1.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 33.    51.2    4.    46.8    3.     1.    51.2    1.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 34.    49.4    3.    46.6    3.     1.    48.     1.     1.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 35.    46.5    2.    39.9    4.     1.    46.5    1.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 36.    52.8    2.    49.9    3.     1.    49.9    0.     1.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 37.    45.     3.    32.9    3.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 38.    55.2    0.    31.     3.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 39.    46.8    9.    38.4    3.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 40.    55.2    5.    33.7    2.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 41.    48.6    9.    37.9    3.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.3], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 42.    53.4    9.    37.4    4.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.1], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 43.    53.4    9.    39.7    4.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.4], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 44.    52.2    0.    37.8    3.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 45.    47.2    3.    24.6    4.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 46.    43.1    3.    29.9    2.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 47.    52.6    9.    36.     3.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.9], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 48.    58.6    5.    32.5    2.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.5], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 49.    44.7    9.    40.2    4.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.2], Reward: 0.0, Period End: False\n",
      "Rnd: 0, Period: 2, New State: [ 50.    46.9    9.    28.5    4.     0.    -1.     0.     0.    25.7\n",
      " -16.37   0.     7.  ], Action:[0.7], Reward: 0.0, Period End: True\n"
     ]
    }
   ],
   "source": [
    "# Random play\n",
    "rnd = 0\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "observation, info = env.reset()\n",
    "for period in count():\n",
    "    for timestep in count(): \n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info, _ = env.step(action)\n",
    "        print(f\"Rnd: {rnd}, Period: {period}, New State: {observation}, Action:{np.round(action,1)}, Reward: {np.round(reward,1)}, Period End: {done}\")\n",
    "        if done:\n",
    "            # If the episode is done, reset the environment\n",
    "            #print('done')\n",
    "            observation, info = env.reset()\n",
    "            break\n",
    "    if period == nperiods:\n",
    "        period = 0\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8540088f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>581</td>\n",
       "      <td>1649.17</td>\n",
       "      <td>996.0</td>\n",
       "      <td>142</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>1093.22</td>\n",
       "      <td>21</td>\n",
       "      <td>72.58</td>\n",
       "      <td>465.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>374</td>\n",
       "      <td>1878.50</td>\n",
       "      <td>873.3</td>\n",
       "      <td>104</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>1377.65</td>\n",
       "      <td>27</td>\n",
       "      <td>717.85</td>\n",
       "      <td>586.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>543</td>\n",
       "      <td>1011.20</td>\n",
       "      <td>862.4</td>\n",
       "      <td>92</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>703.25</td>\n",
       "      <td>15</td>\n",
       "      <td>306.85</td>\n",
       "      <td>200.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1268</td>\n",
       "      <td>2174.80</td>\n",
       "      <td>1869.9</td>\n",
       "      <td>191</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>1326.05</td>\n",
       "      <td>27</td>\n",
       "      <td>458.35</td>\n",
       "      <td>336.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>909</td>\n",
       "      <td>1594.50</td>\n",
       "      <td>1318.8</td>\n",
       "      <td>166</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>867.90</td>\n",
       "      <td>18</td>\n",
       "      <td>327.60</td>\n",
       "      <td>290.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0      24   581      1649.17        996.0              142   \n",
       "1                  0      27   374      1878.50        873.3              104   \n",
       "2                  0      23   543      1011.20        862.4               92   \n",
       "3                  0      44  1268      2174.80       1869.9              191   \n",
       "4                  0      32   909      1594.50       1318.8              166   \n",
       "\n",
       "                 buy  sell    price  sale  bprofit  sprofit  \n",
       "current_bid_idx                                              \n",
       "0                 16    21  1093.22    21    72.58   465.82  \n",
       "1                 27    26  1377.65    27   717.85   586.45  \n",
       "2                 15    12   703.25    15   306.85   200.55  \n",
       "3                 26    24  1326.05    27   458.35   336.45  \n",
       "4                 18    15   867.90    18   327.60   290.20  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.head(1000).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7b34a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "rnd = 0\n",
    "period = 0\n",
    "num_states = nsteps\n",
    "min_frac = 0.01\n",
    "max_frac = 1.5\n",
    "eval_steps = 1000\n",
    "training_step = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad71ec",
   "metadata": {},
   "source": [
    "### Continous Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e856dcad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import SAC, DDPG, TD3, A2C, PPO\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "policy_kwargs = dict(net_arch=dict(pi=[128, 128], qf=[128, 128]))\n",
    "model = SAC(\"Ln MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, batch_size=128, action_noise = action_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e1413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843d11406dde4947b76a91d502740ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 154      |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 80       |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 200      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.91    |\n",
      "|    critic_loss     | 51.7     |\n",
      "|    ent_coef        | 0.991    |\n",
      "|    ent_coef_loss   | -0.0147  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 99       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 166      |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 400      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.31    |\n",
      "|    critic_loss     | 39.7     |\n",
      "|    ent_coef        | 0.941    |\n",
      "|    ent_coef_loss   | -0.0992  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 299      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 600      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.98    |\n",
      "|    critic_loss     | 40.3     |\n",
      "|    ent_coef        | 0.891    |\n",
      "|    ent_coef_loss   | -0.182   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 499      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 157      |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 57       |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.3    |\n",
      "|    critic_loss     | 52.5     |\n",
      "|    ent_coef        | 0.844    |\n",
      "|    ent_coef_loss   | -0.238   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 156      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 56       |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.5    |\n",
      "|    critic_loss     | 45.2     |\n",
      "|    ent_coef        | 0.802    |\n",
      "|    ent_coef_loss   | -0.286   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 899      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 146      |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 55       |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 1200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.5    |\n",
      "|    critic_loss     | 27.4     |\n",
      "|    ent_coef        | 0.763    |\n",
      "|    ent_coef_loss   | -0.264   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 1400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16      |\n",
      "|    critic_loss     | 40       |\n",
      "|    ent_coef        | 0.725    |\n",
      "|    ent_coef_loss   | -0.365   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 1600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.7    |\n",
      "|    critic_loss     | 30.8     |\n",
      "|    ent_coef        | 0.687    |\n",
      "|    ent_coef_loss   | -0.516   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 1800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.3    |\n",
      "|    critic_loss     | 42.3     |\n",
      "|    ent_coef        | 0.649    |\n",
      "|    ent_coef_loss   | -0.589   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.5    |\n",
      "|    critic_loss     | 32.6     |\n",
      "|    ent_coef        | 0.613    |\n",
      "|    ent_coef_loss   | -0.686   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 2200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.3    |\n",
      "|    critic_loss     | 88.3     |\n",
      "|    ent_coef        | 0.578    |\n",
      "|    ent_coef_loss   | -0.692   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 2400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.4    |\n",
      "|    critic_loss     | 15.4     |\n",
      "|    ent_coef        | 0.545    |\n",
      "|    ent_coef_loss   | -0.838   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 2600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.8    |\n",
      "|    critic_loss     | 49.7     |\n",
      "|    ent_coef        | 0.514    |\n",
      "|    ent_coef_loss   | -0.82    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 2800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.2    |\n",
      "|    critic_loss     | 24.1     |\n",
      "|    ent_coef        | 0.485    |\n",
      "|    ent_coef_loss   | -0.923   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.4    |\n",
      "|    critic_loss     | 24.8     |\n",
      "|    ent_coef        | 0.458    |\n",
      "|    ent_coef_loss   | -1.01    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2899     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 3200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.8    |\n",
      "|    critic_loss     | 47.2     |\n",
      "|    ent_coef        | 0.433    |\n",
      "|    ent_coef_loss   | -1.04    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 145      |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 3400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.3    |\n",
      "|    critic_loss     | 15.7     |\n",
      "|    ent_coef        | 0.409    |\n",
      "|    ent_coef_loss   | -1.24    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 146      |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 3600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16      |\n",
      "|    critic_loss     | 22.4     |\n",
      "|    ent_coef        | 0.385    |\n",
      "|    ent_coef_loss   | -0.997   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 3800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.3    |\n",
      "|    critic_loss     | 22.5     |\n",
      "|    ent_coef        | 0.362    |\n",
      "|    ent_coef_loss   | -1.41    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 146      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17      |\n",
      "|    critic_loss     | 22.4     |\n",
      "|    ent_coef        | 0.34     |\n",
      "|    ent_coef_loss   | -1.62    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 4200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.6    |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    ent_coef        | 0.319    |\n",
      "|    ent_coef_loss   | -1.58    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 4400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.8    |\n",
      "|    critic_loss     | 14       |\n",
      "|    ent_coef        | 0.3      |\n",
      "|    ent_coef_loss   | -1.6     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 4600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.1    |\n",
      "|    critic_loss     | 13.7     |\n",
      "|    ent_coef        | 0.283    |\n",
      "|    ent_coef_loss   | -1.6     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20.6    |\n",
      "|    critic_loss     | 16.8     |\n",
      "|    ent_coef        | 0.267    |\n",
      "|    ent_coef_loss   | -1.52    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 149      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 98       |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.8    |\n",
      "|    critic_loss     | 8.17     |\n",
      "|    ent_coef        | 0.251    |\n",
      "|    ent_coef_loss   | -1.92    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 102      |\n",
      "|    total_timesteps | 5200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.1    |\n",
      "|    critic_loss     | 8.76     |\n",
      "|    ent_coef        | 0.237    |\n",
      "|    ent_coef_loss   | -1.83    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 149      |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 5400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24      |\n",
      "|    critic_loss     | 28       |\n",
      "|    ent_coef        | 0.223    |\n",
      "|    ent_coef_loss   | -1.91    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.8    |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    ent_coef        | 0.211    |\n",
      "|    ent_coef_loss   | -1.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 149      |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 5800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16      |\n",
      "|    critic_loss     | 9.55     |\n",
      "|    ent_coef        | 0.199    |\n",
      "|    ent_coef_loss   | -2.19    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.6    |\n",
      "|    critic_loss     | 25.6     |\n",
      "|    ent_coef        | 0.188    |\n",
      "|    ent_coef_loss   | -2.07    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5899     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 153      |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 6200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.5    |\n",
      "|    critic_loss     | 16.1     |\n",
      "|    ent_coef        | 0.178    |\n",
      "|    ent_coef_loss   | -2.19    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 154      |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19      |\n",
      "|    critic_loss     | 19.1     |\n",
      "|    ent_coef        | 0.168    |\n",
      "|    ent_coef_loss   | -2.12    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 154      |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 6600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.8    |\n",
      "|    critic_loss     | 16       |\n",
      "|    ent_coef        | 0.159    |\n",
      "|    ent_coef_loss   | -2.26    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 157      |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 6800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.2    |\n",
      "|    critic_loss     | 19.1     |\n",
      "|    ent_coef        | 0.151    |\n",
      "|    ent_coef_loss   | -2.31    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 159      |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    ent_coef        | 0.144    |\n",
      "|    ent_coef_loss   | -1.98    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 161      |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20.7    |\n",
      "|    critic_loss     | 9.25     |\n",
      "|    ent_coef        | 0.137    |\n",
      "|    ent_coef_loss   | -1.31    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 163      |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 7400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.6    |\n",
      "|    critic_loss     | 14       |\n",
      "|    ent_coef        | 0.13     |\n",
      "|    ent_coef_loss   | -2.16    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 163      |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 7600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.7    |\n",
      "|    critic_loss     | 12.1     |\n",
      "|    ent_coef        | 0.124    |\n",
      "|    ent_coef_loss   | -1.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 165      |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 152      |\n",
      "|    total_timesteps | 7800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20.1    |\n",
      "|    critic_loss     | 13.6     |\n",
      "|    ent_coef        | 0.118    |\n",
      "|    ent_coef_loss   | -1.83    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 165      |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.9    |\n",
      "|    critic_loss     | 9.96     |\n",
      "|    ent_coef        | 0.112    |\n",
      "|    ent_coef_loss   | -2.47    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 8200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -27.8    |\n",
      "|    critic_loss     | 16.6     |\n",
      "|    ent_coef        | 0.107    |\n",
      "|    ent_coef_loss   | -1.45    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 165      |\n",
      "|    total_timesteps | 8400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.2    |\n",
      "|    critic_loss     | 14       |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -1.14    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 166      |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 170      |\n",
      "|    total_timesteps | 8600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.1    |\n",
      "|    critic_loss     | 10.1     |\n",
      "|    ent_coef        | 0.0984   |\n",
      "|    ent_coef_loss   | -1.7     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 167      |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.3    |\n",
      "|    critic_loss     | 15.8     |\n",
      "|    ent_coef        | 0.0938   |\n",
      "|    ent_coef_loss   | -1.5     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 169      |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 178      |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.2    |\n",
      "|    critic_loss     | 7.85     |\n",
      "|    ent_coef        | 0.0893   |\n",
      "|    ent_coef_loss   | -1.35    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8899     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 169      |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 183      |\n",
      "|    total_timesteps | 9200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.9    |\n",
      "|    critic_loss     | 19.1     |\n",
      "|    ent_coef        | 0.0855   |\n",
      "|    ent_coef_loss   | -1.82    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 170      |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 187      |\n",
      "|    total_timesteps | 9400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.1    |\n",
      "|    critic_loss     | 15.7     |\n",
      "|    ent_coef        | 0.0817   |\n",
      "|    ent_coef_loss   | -1.19    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 171      |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 192      |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.7    |\n",
      "|    critic_loss     | 8.35     |\n",
      "|    ent_coef        | 0.0783   |\n",
      "|    ent_coef_loss   | -1.45    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 174      |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 196      |\n",
      "|    total_timesteps | 9800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.6    |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    ent_coef        | 0.0747   |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 173      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -27.4    |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    ent_coef        | 0.0706   |\n",
      "|    ent_coef_loss   | -1.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 173      |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 205      |\n",
      "|    total_timesteps | 10200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.3    |\n",
      "|    critic_loss     | 12.1     |\n",
      "|    ent_coef        | 0.0674   |\n",
      "|    ent_coef_loss   | -1.91    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 174      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 210      |\n",
      "|    total_timesteps | 10400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.7    |\n",
      "|    critic_loss     | 10.1     |\n",
      "|    ent_coef        | 0.0642   |\n",
      "|    ent_coef_loss   | -2.39    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 174      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 214      |\n",
      "|    total_timesteps | 10600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -27      |\n",
      "|    critic_loss     | 12.6     |\n",
      "|    ent_coef        | 0.0612   |\n",
      "|    ent_coef_loss   | -2.23    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 177      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 218      |\n",
      "|    total_timesteps | 10800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.4    |\n",
      "|    critic_loss     | 19       |\n",
      "|    ent_coef        | 0.0587   |\n",
      "|    ent_coef_loss   | -1.64    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 176      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 11000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26      |\n",
      "|    critic_loss     | 16.1     |\n",
      "|    ent_coef        | 0.0565   |\n",
      "|    ent_coef_loss   | -0.767   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 178      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 11200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.9    |\n",
      "|    critic_loss     | 15       |\n",
      "|    ent_coef        | 0.0546   |\n",
      "|    ent_coef_loss   | -1.55    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 179      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 11400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.2    |\n",
      "|    critic_loss     | 20.9     |\n",
      "|    ent_coef        | 0.0527   |\n",
      "|    ent_coef_loss   | -0.104   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 238      |\n",
      "|    total_timesteps | 11600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.9    |\n",
      "|    critic_loss     | 11.9     |\n",
      "|    ent_coef        | 0.0509   |\n",
      "|    ent_coef_loss   | -1.75    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 181      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 243      |\n",
      "|    total_timesteps | 11800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.6    |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    ent_coef        | 0.0493   |\n",
      "|    ent_coef_loss   | -1.59    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 182      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 249      |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.9    |\n",
      "|    critic_loss     | 20       |\n",
      "|    ent_coef        | 0.0477   |\n",
      "|    ent_coef_loss   | -0.584   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11899    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 182      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 254      |\n",
      "|    total_timesteps | 12200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -35.9    |\n",
      "|    critic_loss     | 15       |\n",
      "|    ent_coef        | 0.0458   |\n",
      "|    ent_coef_loss   | -1.09    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 183      |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 262      |\n",
      "|    total_timesteps | 12400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -35.8    |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    ent_coef        | 0.0449   |\n",
      "|    ent_coef_loss   | -1.31    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 184      |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 12600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -32.5    |\n",
      "|    critic_loss     | 8.61     |\n",
      "|    ent_coef        | 0.0438   |\n",
      "|    ent_coef_loss   | -0.221   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 186      |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 274      |\n",
      "|    total_timesteps | 12800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -42.4    |\n",
      "|    critic_loss     | 20.6     |\n",
      "|    ent_coef        | 0.0433   |\n",
      "|    ent_coef_loss   | -0.165   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 187      |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 280      |\n",
      "|    total_timesteps | 13000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -32.6    |\n",
      "|    critic_loss     | 23.9     |\n",
      "|    ent_coef        | 0.0425   |\n",
      "|    ent_coef_loss   | -0.781   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 284      |\n",
      "|    total_timesteps | 13200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -33.3    |\n",
      "|    critic_loss     | 16.8     |\n",
      "|    ent_coef        | 0.0416   |\n",
      "|    ent_coef_loss   | -0.119   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 189      |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 13400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -34.1    |\n",
      "|    critic_loss     | 13.2     |\n",
      "|    ent_coef        | 0.0402   |\n",
      "|    ent_coef_loss   | -0.404   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 13600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -37.2    |\n",
      "|    critic_loss     | 16.1     |\n",
      "|    ent_coef        | 0.0395   |\n",
      "|    ent_coef_loss   | -0.855   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 13800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.2    |\n",
      "|    critic_loss     | 11.6     |\n",
      "|    ent_coef        | 0.0388   |\n",
      "|    ent_coef_loss   | -0.121   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 190      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 301      |\n",
      "|    total_timesteps | 14000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.4    |\n",
      "|    critic_loss     | 9.95     |\n",
      "|    ent_coef        | 0.038    |\n",
      "|    ent_coef_loss   | 0.63     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 191      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 14200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.1    |\n",
      "|    critic_loss     | 5.78     |\n",
      "|    ent_coef        | 0.0373   |\n",
      "|    ent_coef_loss   | 0.271    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 192      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 310      |\n",
      "|    total_timesteps | 14400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -36.3    |\n",
      "|    critic_loss     | 15.5     |\n",
      "|    ent_coef        | 0.0367   |\n",
      "|    ent_coef_loss   | 0.0228   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 192      |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 320      |\n",
      "|    total_timesteps | 14800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.3    |\n",
      "|    critic_loss     | 14.4     |\n",
      "|    ent_coef        | 0.0361   |\n",
      "|    ent_coef_loss   | 0.241    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 195      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 327      |\n",
      "|    total_timesteps | 15000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -39.9    |\n",
      "|    critic_loss     | 15.9     |\n",
      "|    ent_coef        | 0.0365   |\n",
      "|    ent_coef_loss   | 0.00638  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 197      |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 332      |\n",
      "|    total_timesteps | 15200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -38.8    |\n",
      "|    critic_loss     | 13.7     |\n",
      "|    ent_coef        | 0.0359   |\n",
      "|    ent_coef_loss   | -0.112   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15099    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 199      |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 337      |\n",
      "|    total_timesteps | 15400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -35.6    |\n",
      "|    critic_loss     | 16.9     |\n",
      "|    ent_coef        | 0.0357   |\n",
      "|    ent_coef_loss   | -0.297   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 201      |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 342      |\n",
      "|    total_timesteps | 15600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43      |\n",
      "|    critic_loss     | 14.8     |\n",
      "|    ent_coef        | 0.0357   |\n",
      "|    ent_coef_loss   | -0.193   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 203      |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 15800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -40.2    |\n",
      "|    critic_loss     | 18.7     |\n",
      "|    ent_coef        | 0.0361   |\n",
      "|    ent_coef_loss   | 0.665    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 205      |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 351      |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43.5    |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    ent_coef        | 0.037    |\n",
      "|    ent_coef_loss   | 1.04     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 206      |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 16200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43      |\n",
      "|    critic_loss     | 13       |\n",
      "|    ent_coef        | 0.0374   |\n",
      "|    ent_coef_loss   | 0.703    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 207      |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 361      |\n",
      "|    total_timesteps | 16400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -36      |\n",
      "|    critic_loss     | 14.9     |\n",
      "|    ent_coef        | 0.0383   |\n",
      "|    ent_coef_loss   | 0.377    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 210      |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 366      |\n",
      "|    total_timesteps | 16600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -39      |\n",
      "|    critic_loss     | 14       |\n",
      "|    ent_coef        | 0.0387   |\n",
      "|    ent_coef_loss   | -1.28    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 210      |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 16800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -40.8    |\n",
      "|    critic_loss     | 9.1      |\n",
      "|    ent_coef        | 0.0382   |\n",
      "|    ent_coef_loss   | -0.614   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 211      |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 376      |\n",
      "|    total_timesteps | 17000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -42.3    |\n",
      "|    critic_loss     | 9.3      |\n",
      "|    ent_coef        | 0.038    |\n",
      "|    ent_coef_loss   | -0.381   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 381      |\n",
      "|    total_timesteps | 17200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43.2    |\n",
      "|    critic_loss     | 19.2     |\n",
      "|    ent_coef        | 0.0381   |\n",
      "|    ent_coef_loss   | 1.43     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 216      |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 386      |\n",
      "|    total_timesteps | 17400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -48.8    |\n",
      "|    critic_loss     | 19.6     |\n",
      "|    ent_coef        | 0.0377   |\n",
      "|    ent_coef_loss   | -0.612   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 217      |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 391      |\n",
      "|    total_timesteps | 17600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -44.9    |\n",
      "|    critic_loss     | 23.4     |\n",
      "|    ent_coef        | 0.0368   |\n",
      "|    ent_coef_loss   | -0.501   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 219      |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 397      |\n",
      "|    total_timesteps | 17800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -41.7    |\n",
      "|    critic_loss     | 16.5     |\n",
      "|    ent_coef        | 0.0359   |\n",
      "|    ent_coef_loss   | -0.913   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 219      |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 403      |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.9    |\n",
      "|    critic_loss     | 18.4     |\n",
      "|    ent_coef        | 0.0347   |\n",
      "|    ent_coef_loss   | 1.47     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 220      |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 409      |\n",
      "|    total_timesteps | 18200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -44.6    |\n",
      "|    critic_loss     | 19.4     |\n",
      "|    ent_coef        | 0.034    |\n",
      "|    ent_coef_loss   | -0.376   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18099    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 221      |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 414      |\n",
      "|    total_timesteps | 18400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.4    |\n",
      "|    critic_loss     | 14.9     |\n",
      "|    ent_coef        | 0.0329   |\n",
      "|    ent_coef_loss   | -0.25    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 222      |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 419      |\n",
      "|    total_timesteps | 18600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -45.3    |\n",
      "|    critic_loss     | 19.9     |\n",
      "|    ent_coef        | 0.0324   |\n",
      "|    ent_coef_loss   | -0.558   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 225      |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 423      |\n",
      "|    total_timesteps | 18800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -42.4    |\n",
      "|    critic_loss     | 9.36     |\n",
      "|    ent_coef        | 0.031    |\n",
      "|    ent_coef_loss   | 0.332    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 226      |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 427      |\n",
      "|    total_timesteps | 19000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -44.3    |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    ent_coef        | 0.0297   |\n",
      "|    ent_coef_loss   | -0.61    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 431      |\n",
      "|    total_timesteps | 19200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.7    |\n",
      "|    critic_loss     | 32.8     |\n",
      "|    ent_coef        | 0.0283   |\n",
      "|    ent_coef_loss   | -0.533   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 436      |\n",
      "|    total_timesteps | 19400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -44.4    |\n",
      "|    critic_loss     | 11.3     |\n",
      "|    ent_coef        | 0.0274   |\n",
      "|    ent_coef_loss   | 0.0185   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 233      |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 440      |\n",
      "|    total_timesteps | 19600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -47.4    |\n",
      "|    critic_loss     | 20       |\n",
      "|    ent_coef        | 0.0266   |\n",
      "|    ent_coef_loss   | -0.202   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 235      |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 445      |\n",
      "|    total_timesteps | 19800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -51.4    |\n",
      "|    critic_loss     | 17.8     |\n",
      "|    ent_coef        | 0.0262   |\n",
      "|    ent_coef_loss   | -0.479   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 237      |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 450      |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -41      |\n",
      "|    critic_loss     | 23.7     |\n",
      "|    ent_coef        | 0.026    |\n",
      "|    ent_coef_loss   | 0.729    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 455      |\n",
      "|    total_timesteps | 20200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -56.7    |\n",
      "|    critic_loss     | 23.2     |\n",
      "|    ent_coef        | 0.026    |\n",
      "|    ent_coef_loss   | -0.527   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 240      |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 460      |\n",
      "|    total_timesteps | 20400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43.9    |\n",
      "|    critic_loss     | 18.9     |\n",
      "|    ent_coef        | 0.0259   |\n",
      "|    ent_coef_loss   | -0.484   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 241      |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 465      |\n",
      "|    total_timesteps | 20600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.2    |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    ent_coef        | 0.0258   |\n",
      "|    ent_coef_loss   | 0.361    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 242      |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 470      |\n",
      "|    total_timesteps | 20800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -49.1    |\n",
      "|    critic_loss     | 21.6     |\n",
      "|    ent_coef        | 0.0256   |\n",
      "|    ent_coef_loss   | 0.0298   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 244      |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 476      |\n",
      "|    total_timesteps | 21000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.6    |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    ent_coef        | 0.0253   |\n",
      "|    ent_coef_loss   | -0.442   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 481      |\n",
      "|    total_timesteps | 21200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.1    |\n",
      "|    critic_loss     | 16       |\n",
      "|    ent_coef        | 0.0255   |\n",
      "|    ent_coef_loss   | 0.561    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21099    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 485      |\n",
      "|    total_timesteps | 21400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43.2    |\n",
      "|    critic_loss     | 13.7     |\n",
      "|    ent_coef        | 0.0259   |\n",
      "|    ent_coef_loss   | -0.454   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 491      |\n",
      "|    total_timesteps | 21600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -50.6    |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    ent_coef        | 0.0259   |\n",
      "|    ent_coef_loss   | 0.119    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 496      |\n",
      "|    total_timesteps | 21800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -45.6    |\n",
      "|    critic_loss     | 11.3     |\n",
      "|    ent_coef        | 0.0265   |\n",
      "|    ent_coef_loss   | 0.134    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 501      |\n",
      "|    total_timesteps | 22000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -51.3    |\n",
      "|    critic_loss     | 17.1     |\n",
      "|    ent_coef        | 0.0272   |\n",
      "|    ent_coef_loss   | 0.631    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 507      |\n",
      "|    total_timesteps | 22200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -47.4    |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    ent_coef        | 0.0278   |\n",
      "|    ent_coef_loss   | 0.425    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 448      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 511      |\n",
      "|    total_timesteps | 22400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.2    |\n",
      "|    critic_loss     | 14.8     |\n",
      "|    ent_coef        | 0.0286   |\n",
      "|    ent_coef_loss   | -0.266   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 452      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 516      |\n",
      "|    total_timesteps | 22600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -44.2    |\n",
      "|    critic_loss     | 20.4     |\n",
      "|    ent_coef        | 0.0298   |\n",
      "|    ent_coef_loss   | -0.124   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 456      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 520      |\n",
      "|    total_timesteps | 22800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -50.5    |\n",
      "|    critic_loss     | 21       |\n",
      "|    ent_coef        | 0.0307   |\n",
      "|    ent_coef_loss   | 0.468    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 525      |\n",
      "|    total_timesteps | 23000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.9    |\n",
      "|    critic_loss     | 22.3     |\n",
      "|    ent_coef        | 0.0317   |\n",
      "|    ent_coef_loss   | 0.255    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 263      |\n",
      "| time/              |          |\n",
      "|    episodes        | 464      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 530      |\n",
      "|    total_timesteps | 23200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59      |\n",
      "|    critic_loss     | 8.84     |\n",
      "|    ent_coef        | 0.0329   |\n",
      "|    ent_coef_loss   | 0.0107   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 265      |\n",
      "| time/              |          |\n",
      "|    episodes        | 468      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 535      |\n",
      "|    total_timesteps | 23400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -61.7    |\n",
      "|    critic_loss     | 13.8     |\n",
      "|    ent_coef        | 0.0341   |\n",
      "|    ent_coef_loss   | 0.212    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 472      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 540      |\n",
      "|    total_timesteps | 23600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -56.9    |\n",
      "|    critic_loss     | 11.9     |\n",
      "|    ent_coef        | 0.0354   |\n",
      "|    ent_coef_loss   | 0.457    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 476      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 545      |\n",
      "|    total_timesteps | 23800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57.3    |\n",
      "|    critic_loss     | 29.1     |\n",
      "|    ent_coef        | 0.0366   |\n",
      "|    ent_coef_loss   | -0.0274  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 550      |\n",
      "|    total_timesteps | 24000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -61.7    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    ent_coef        | 0.0386   |\n",
      "|    ent_coef_loss   | 0.129    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 484      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 555      |\n",
      "|    total_timesteps | 24200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -61.6    |\n",
      "|    critic_loss     | 17.7     |\n",
      "|    ent_coef        | 0.0401   |\n",
      "|    ent_coef_loss   | 0.519    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24099    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 488      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 560      |\n",
      "|    total_timesteps | 24400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -53.6    |\n",
      "|    critic_loss     | 12.6     |\n",
      "|    ent_coef        | 0.0417   |\n",
      "|    ent_coef_loss   | 0.623    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 492      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 566      |\n",
      "|    total_timesteps | 24600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -51.8    |\n",
      "|    critic_loss     | 13.2     |\n",
      "|    ent_coef        | 0.0437   |\n",
      "|    ent_coef_loss   | 0.218    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 496      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 571      |\n",
      "|    total_timesteps | 24800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59.3    |\n",
      "|    critic_loss     | 13.3     |\n",
      "|    ent_coef        | 0.045    |\n",
      "|    ent_coef_loss   | -0.21    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 578      |\n",
      "|    total_timesteps | 25000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -65.4    |\n",
      "|    critic_loss     | 14.5     |\n",
      "|    ent_coef        | 0.0466   |\n",
      "|    ent_coef_loss   | 0.855    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 504      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 583      |\n",
      "|    total_timesteps | 25200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66      |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    ent_coef        | 0.049    |\n",
      "|    ent_coef_loss   | -0.0828  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 508      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 589      |\n",
      "|    total_timesteps | 25400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -69      |\n",
      "|    critic_loss     | 13.5     |\n",
      "|    ent_coef        | 0.0513   |\n",
      "|    ent_coef_loss   | 0.541    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 512      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 594      |\n",
      "|    total_timesteps | 25600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -65.6    |\n",
      "|    critic_loss     | 14.3     |\n",
      "|    ent_coef        | 0.0534   |\n",
      "|    ent_coef_loss   | -0.0555  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 516      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 599      |\n",
      "|    total_timesteps | 25800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.3    |\n",
      "|    critic_loss     | 10.3     |\n",
      "|    ent_coef        | 0.0551   |\n",
      "|    ent_coef_loss   | 0.278    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 604      |\n",
      "|    total_timesteps | 26000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -60.9    |\n",
      "|    critic_loss     | 29.2     |\n",
      "|    ent_coef        | 0.0576   |\n",
      "|    ent_coef_loss   | 0.297    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 524      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 608      |\n",
      "|    total_timesteps | 26200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66      |\n",
      "|    critic_loss     | 16.2     |\n",
      "|    ent_coef        | 0.0602   |\n",
      "|    ent_coef_loss   | 0.495    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 528      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 613      |\n",
      "|    total_timesteps | 26400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -65.6    |\n",
      "|    critic_loss     | 12.7     |\n",
      "|    ent_coef        | 0.0629   |\n",
      "|    ent_coef_loss   | 0.718    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 532      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 618      |\n",
      "|    total_timesteps | 26600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67      |\n",
      "|    critic_loss     | 10.8     |\n",
      "|    ent_coef        | 0.065    |\n",
      "|    ent_coef_loss   | 0.59     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 536      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 622      |\n",
      "|    total_timesteps | 26800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -72      |\n",
      "|    critic_loss     | 8.43     |\n",
      "|    ent_coef        | 0.0674   |\n",
      "|    ent_coef_loss   | 0.102    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 627      |\n",
      "|    total_timesteps | 27000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68      |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    ent_coef        | 0.0697   |\n",
      "|    ent_coef_loss   | -0.154   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 544      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 632      |\n",
      "|    total_timesteps | 27200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59.6    |\n",
      "|    critic_loss     | 69.7     |\n",
      "|    ent_coef        | 0.072    |\n",
      "|    ent_coef_loss   | -0.123   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27099    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 548      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 637      |\n",
      "|    total_timesteps | 27400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -69.4    |\n",
      "|    critic_loss     | 14.4     |\n",
      "|    ent_coef        | 0.0747   |\n",
      "|    ent_coef_loss   | 0.432    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 552      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 642      |\n",
      "|    total_timesteps | 27600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58      |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    ent_coef        | 0.0772   |\n",
      "|    ent_coef_loss   | -0.258   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 556      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 648      |\n",
      "|    total_timesteps | 27800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.9    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    ent_coef        | 0.08     |\n",
      "|    ent_coef_loss   | -0.177   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 654      |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.1    |\n",
      "|    critic_loss     | 9.55     |\n",
      "|    ent_coef        | 0.0809   |\n",
      "|    ent_coef_loss   | 0.595    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 564      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 659      |\n",
      "|    total_timesteps | 28200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.1    |\n",
      "|    critic_loss     | 20.3     |\n",
      "|    ent_coef        | 0.0832   |\n",
      "|    ent_coef_loss   | 0.752    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 28099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 568      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 664      |\n",
      "|    total_timesteps | 28400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.3    |\n",
      "|    critic_loss     | 21.7     |\n",
      "|    ent_coef        | 0.0858   |\n",
      "|    ent_coef_loss   | 0.297    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 28299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 576      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 675      |\n",
      "|    total_timesteps | 28800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -65.8    |\n",
      "|    critic_loss     | 9.32     |\n",
      "|    ent_coef        | 0.0885   |\n",
      "|    ent_coef_loss   | 0.493    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 28699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 681      |\n",
      "|    total_timesteps | 29000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67.6    |\n",
      "|    critic_loss     | 13.2     |\n",
      "|    ent_coef        | 0.0905   |\n",
      "|    ent_coef_loss   | -0.0867  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 28899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 584      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 686      |\n",
      "|    total_timesteps | 29200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63.2    |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    ent_coef        | 0.0921   |\n",
      "|    ent_coef_loss   | 0.132    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 588      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 691      |\n",
      "|    total_timesteps | 29400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.3    |\n",
      "|    critic_loss     | 12.1     |\n",
      "|    ent_coef        | 0.0927   |\n",
      "|    ent_coef_loss   | 0.363    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 592      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 695      |\n",
      "|    total_timesteps | 29600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -72.3    |\n",
      "|    critic_loss     | 13.7     |\n",
      "|    ent_coef        | 0.0933   |\n",
      "|    ent_coef_loss   | -0.183   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 596      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 700      |\n",
      "|    total_timesteps | 29800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -69.2    |\n",
      "|    critic_loss     | 18.6     |\n",
      "|    ent_coef        | 0.095    |\n",
      "|    ent_coef_loss   | 0.232    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 705      |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.5    |\n",
      "|    critic_loss     | 15.7     |\n",
      "|    ent_coef        | 0.0953   |\n",
      "|    ent_coef_loss   | -0.354   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 604      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 710      |\n",
      "|    total_timesteps | 30200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.3    |\n",
      "|    critic_loss     | 16.1     |\n",
      "|    ent_coef        | 0.0955   |\n",
      "|    ent_coef_loss   | 0.106    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 608      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 715      |\n",
      "|    total_timesteps | 30400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78.7    |\n",
      "|    critic_loss     | 75.3     |\n",
      "|    ent_coef        | 0.0955   |\n",
      "|    ent_coef_loss   | -0.147   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30299    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 612      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 720      |\n",
      "|    total_timesteps | 30600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -70.8    |\n",
      "|    critic_loss     | 8.59     |\n",
      "|    ent_coef        | 0.0956   |\n",
      "|    ent_coef_loss   | -0.525   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 616      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 724      |\n",
      "|    total_timesteps | 30800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.5    |\n",
      "|    critic_loss     | 7.04     |\n",
      "|    ent_coef        | 0.0959   |\n",
      "|    ent_coef_loss   | -0.143   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 729      |\n",
      "|    total_timesteps | 31000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.2    |\n",
      "|    critic_loss     | 12.7     |\n",
      "|    ent_coef        | 0.0951   |\n",
      "|    ent_coef_loss   | 0.028    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 266      |\n",
      "| time/              |          |\n",
      "|    episodes        | 624      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 734      |\n",
      "|    total_timesteps | 31200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.8    |\n",
      "|    critic_loss     | 4.67     |\n",
      "|    ent_coef        | 0.0954   |\n",
      "|    ent_coef_loss   | 0.152    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 31099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 628      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 739      |\n",
      "|    total_timesteps | 31400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.8    |\n",
      "|    critic_loss     | 12.2     |\n",
      "|    ent_coef        | 0.0962   |\n",
      "|    ent_coef_loss   | -0.106   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 31299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 632      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 744      |\n",
      "|    total_timesteps | 31600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.1    |\n",
      "|    critic_loss     | 5.55     |\n",
      "|    ent_coef        | 0.0964   |\n",
      "|    ent_coef_loss   | 0.148    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 31499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 636      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 749      |\n",
      "|    total_timesteps | 31800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.2    |\n",
      "|    critic_loss     | 11.4     |\n",
      "|    ent_coef        | 0.0968   |\n",
      "|    ent_coef_loss   | 0.106    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 31699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 753      |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -75      |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    ent_coef        | 0.0965   |\n",
      "|    ent_coef_loss   | -0.11    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 31899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 644      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 758      |\n",
      "|    total_timesteps | 32200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.6    |\n",
      "|    critic_loss     | 8.49     |\n",
      "|    ent_coef        | 0.097    |\n",
      "|    ent_coef_loss   | -0.388   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 648      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 763      |\n",
      "|    total_timesteps | 32400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.4    |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    ent_coef        | 0.0972   |\n",
      "|    ent_coef_loss   | -0.0871  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 652      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 768      |\n",
      "|    total_timesteps | 32600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.5    |\n",
      "|    critic_loss     | 6.79     |\n",
      "|    ent_coef        | 0.0959   |\n",
      "|    ent_coef_loss   | 0.27     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 656      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 773      |\n",
      "|    total_timesteps | 32800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.6    |\n",
      "|    critic_loss     | 18.4     |\n",
      "|    ent_coef        | 0.0952   |\n",
      "|    ent_coef_loss   | 0.311    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 778      |\n",
      "|    total_timesteps | 33000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87.9    |\n",
      "|    critic_loss     | 8.59     |\n",
      "|    ent_coef        | 0.0956   |\n",
      "|    ent_coef_loss   | -0.413   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 664      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 783      |\n",
      "|    total_timesteps | 33200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.3    |\n",
      "|    critic_loss     | 9.6      |\n",
      "|    ent_coef        | 0.095    |\n",
      "|    ent_coef_loss   | -0.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 33099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 668      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 787      |\n",
      "|    total_timesteps | 33400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.7    |\n",
      "|    critic_loss     | 5.45     |\n",
      "|    ent_coef        | 0.0944   |\n",
      "|    ent_coef_loss   | -0.105   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 33299    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 672      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 792      |\n",
      "|    total_timesteps | 33600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.5    |\n",
      "|    critic_loss     | 7.03     |\n",
      "|    ent_coef        | 0.0954   |\n",
      "|    ent_coef_loss   | -0.156   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 33499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 802      |\n",
      "|    total_timesteps | 34000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.1    |\n",
      "|    critic_loss     | 8.45     |\n",
      "|    ent_coef        | 0.0977   |\n",
      "|    ent_coef_loss   | 0.0416   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 33899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 684      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 807      |\n",
      "|    total_timesteps | 34200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.3    |\n",
      "|    critic_loss     | 16.9     |\n",
      "|    ent_coef        | 0.0981   |\n",
      "|    ent_coef_loss   | -0.224   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 688      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 812      |\n",
      "|    total_timesteps | 34400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.6    |\n",
      "|    critic_loss     | 7.47     |\n",
      "|    ent_coef        | 0.0988   |\n",
      "|    ent_coef_loss   | -0.575   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 692      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 817      |\n",
      "|    total_timesteps | 34600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.5    |\n",
      "|    critic_loss     | 12       |\n",
      "|    ent_coef        | 0.0984   |\n",
      "|    ent_coef_loss   | -0.186   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 696      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 822      |\n",
      "|    total_timesteps | 34800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.6    |\n",
      "|    critic_loss     | 7.74     |\n",
      "|    ent_coef        | 0.0995   |\n",
      "|    ent_coef_loss   | 0.155    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 827      |\n",
      "|    total_timesteps | 35000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.9    |\n",
      "|    critic_loss     | 7.29     |\n",
      "|    ent_coef        | 0.1      |\n",
      "|    ent_coef_loss   | -0.126   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 704      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 832      |\n",
      "|    total_timesteps | 35200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.5    |\n",
      "|    critic_loss     | 7        |\n",
      "|    ent_coef        | 0.0995   |\n",
      "|    ent_coef_loss   | 0.441    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 708      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 837      |\n",
      "|    total_timesteps | 35400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.1    |\n",
      "|    critic_loss     | 6.49     |\n",
      "|    ent_coef        | 0.101    |\n",
      "|    ent_coef_loss   | -0.414   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 712      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 842      |\n",
      "|    total_timesteps | 35600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.7    |\n",
      "|    critic_loss     | 5.05     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | -0.273   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 716      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 847      |\n",
      "|    total_timesteps | 35800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.9    |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -0.16    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 852      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.9    |\n",
      "|    critic_loss     | 6.97     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -0.12    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 724      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 858      |\n",
      "|    total_timesteps | 36200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.9    |\n",
      "|    critic_loss     | 56.2     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | 0.134    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 728      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 864      |\n",
      "|    total_timesteps | 36400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.3    |\n",
      "|    critic_loss     | 9.71     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | 0.114    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 732      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 870      |\n",
      "|    total_timesteps | 36600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.7    |\n",
      "|    critic_loss     | 33.7     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | 0.235    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36499    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 736      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 876      |\n",
      "|    total_timesteps | 36800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -83      |\n",
      "|    critic_loss     | 4.41     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | -0.266   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 882      |\n",
      "|    total_timesteps | 37000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.5    |\n",
      "|    critic_loss     | 5.35     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | 0.11     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 744      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 887      |\n",
      "|    total_timesteps | 37200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85      |\n",
      "|    critic_loss     | 6.02     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | 0.371    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 37099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 748      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 893      |\n",
      "|    total_timesteps | 37400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.8    |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | -0.0901  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 37299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 752      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 898      |\n",
      "|    total_timesteps | 37600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.2    |\n",
      "|    critic_loss     | 30.7     |\n",
      "|    ent_coef        | 0.107    |\n",
      "|    ent_coef_loss   | -0.506   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 37499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 756      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 903      |\n",
      "|    total_timesteps | 37800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.6    |\n",
      "|    critic_loss     | 5.6      |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | 0.24     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 37699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 908      |\n",
      "|    total_timesteps | 38000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.7    |\n",
      "|    critic_loss     | 20.8     |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | -0.0233  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 37899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 764      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 914      |\n",
      "|    total_timesteps | 38200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77      |\n",
      "|    critic_loss     | 5.39     |\n",
      "|    ent_coef        | 0.105    |\n",
      "|    ent_coef_loss   | -0.273   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 768      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 921      |\n",
      "|    total_timesteps | 38400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.1    |\n",
      "|    critic_loss     | 5.21     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | -0.0492  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 772      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 929      |\n",
      "|    total_timesteps | 38600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.3    |\n",
      "|    critic_loss     | 4.17     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | -0.285   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 776      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 935      |\n",
      "|    total_timesteps | 38800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.9    |\n",
      "|    critic_loss     | 5.67     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | 0.29     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 944      |\n",
      "|    total_timesteps | 39000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.1    |\n",
      "|    critic_loss     | 6.83     |\n",
      "|    ent_coef        | 0.105    |\n",
      "|    ent_coef_loss   | 0.119    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 784      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 961      |\n",
      "|    total_timesteps | 39200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.9    |\n",
      "|    critic_loss     | 46.5     |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | 0.226    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 788      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 969      |\n",
      "|    total_timesteps | 39400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 10.4     |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | 0.095    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 792      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 974      |\n",
      "|    total_timesteps | 39600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.7    |\n",
      "|    critic_loss     | 10.1     |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | 0.254    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39499    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 796      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 988      |\n",
      "|    total_timesteps | 39800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.8    |\n",
      "|    critic_loss     | 5.78     |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | 0.239    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 999      |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.8    |\n",
      "|    critic_loss     | 5.73     |\n",
      "|    ent_coef        | 0.111    |\n",
      "|    ent_coef_loss   | 0.05     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 804      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1008     |\n",
      "|    total_timesteps | 40200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.5    |\n",
      "|    critic_loss     | 6.79     |\n",
      "|    ent_coef        | 0.112    |\n",
      "|    ent_coef_loss   | 0.225    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 40099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 808      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1014     |\n",
      "|    total_timesteps | 40400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 10.3     |\n",
      "|    ent_coef        | 0.113    |\n",
      "|    ent_coef_loss   | 0.00232  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 40299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 812      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1021     |\n",
      "|    total_timesteps | 40600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 5.31     |\n",
      "|    ent_coef        | 0.116    |\n",
      "|    ent_coef_loss   | 0.232    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 40499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 816      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1030     |\n",
      "|    total_timesteps | 40800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.1    |\n",
      "|    critic_loss     | 7.52     |\n",
      "|    ent_coef        | 0.116    |\n",
      "|    ent_coef_loss   | -0.0819  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 40699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 820      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1039     |\n",
      "|    total_timesteps | 41000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.6    |\n",
      "|    critic_loss     | 9.72     |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | -0.379   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 40899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 824      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1046     |\n",
      "|    total_timesteps | 41200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.8    |\n",
      "|    critic_loss     | 3.85     |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | -0.281   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 41099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 828      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1053     |\n",
      "|    total_timesteps | 41400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.1    |\n",
      "|    critic_loss     | 11       |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | 0.166    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 41299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 832      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1061     |\n",
      "|    total_timesteps | 41600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.2    |\n",
      "|    critic_loss     | 46.9     |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | 0.457    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 41499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 836      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1067     |\n",
      "|    total_timesteps | 41800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78      |\n",
      "|    critic_loss     | 5.78     |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | -0.672   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 41699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 840      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1074     |\n",
      "|    total_timesteps | 42000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88      |\n",
      "|    critic_loss     | 3.96     |\n",
      "|    ent_coef        | 0.116    |\n",
      "|    ent_coef_loss   | 0.406    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 41899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 844      |\n",
      "|    fps             | 38       |\n",
      "|    time_elapsed    | 1082     |\n",
      "|    total_timesteps | 42200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.4    |\n",
      "|    critic_loss     | 8.21     |\n",
      "|    ent_coef        | 0.119    |\n",
      "|    ent_coef_loss   | 0.469    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 42099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 848      |\n",
      "|    fps             | 38       |\n",
      "|    time_elapsed    | 1087     |\n",
      "|    total_timesteps | 42400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.7    |\n",
      "|    critic_loss     | 9.67     |\n",
      "|    ent_coef        | 0.121    |\n",
      "|    ent_coef_loss   | -0.0404  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 42299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 852      |\n",
      "|    fps             | 38       |\n",
      "|    time_elapsed    | 1094     |\n",
      "|    total_timesteps | 42600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 16.3     |\n",
      "|    ent_coef        | 0.122    |\n",
      "|    ent_coef_loss   | 0.152    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 42499    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(50000, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63de39e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>2668</td>\n",
       "      <td>7168.89</td>\n",
       "      <td>4443.3</td>\n",
       "      <td>589</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>4857.39</td>\n",
       "      <td>91</td>\n",
       "      <td>92.41</td>\n",
       "      <td>1807.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "      <td>1176</td>\n",
       "      <td>4361.80</td>\n",
       "      <td>2628.6</td>\n",
       "      <td>339</td>\n",
       "      <td>69</td>\n",
       "      <td>67</td>\n",
       "      <td>3417.30</td>\n",
       "      <td>70</td>\n",
       "      <td>1511.70</td>\n",
       "      <td>1133.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>4170</td>\n",
       "      <td>5947.30</td>\n",
       "      <td>5853.7</td>\n",
       "      <td>669</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>2094.10</td>\n",
       "      <td>44</td>\n",
       "      <td>903.10</td>\n",
       "      <td>705.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>435</td>\n",
       "      <td>2171</td>\n",
       "      <td>5084.70</td>\n",
       "      <td>3547.3</td>\n",
       "      <td>521</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>2934.50</td>\n",
       "      <td>60</td>\n",
       "      <td>1529.50</td>\n",
       "      <td>1237.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>2065</td>\n",
       "      <td>4796.40</td>\n",
       "      <td>3285.7</td>\n",
       "      <td>430</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>2458.35</td>\n",
       "      <td>49</td>\n",
       "      <td>1449.05</td>\n",
       "      <td>1144.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0     490  2668      7168.89       4443.3              589   \n",
       "1                  0     329  1176      4361.80       2628.6              339   \n",
       "2                  0     607  4170      5947.30       5853.7              669   \n",
       "3                  0     435  2171      5084.70       3547.3              521   \n",
       "4                  0     389  2065      4796.40       3285.7              430   \n",
       "\n",
       "                 buy  sell    price  sale  bprofit  sprofit  \n",
       "current_bid_idx                                              \n",
       "0                 60    90  4857.39    91    92.41  1807.99  \n",
       "1                 69    67  3417.30    70  1511.70  1133.10  \n",
       "2                 39    41  2094.10    44   903.10   705.40  \n",
       "3                 60    57  2934.50    60  1529.50  1237.20  \n",
       "4                 47    47  2458.35    49  1449.05  1144.75  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.head(500).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52b6bcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56744</td>\n",
       "      <td>1313</td>\n",
       "      <td>2922.51</td>\n",
       "      <td>2446.3</td>\n",
       "      <td>313</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>2238.795</td>\n",
       "      <td>52</td>\n",
       "      <td>1106.005</td>\n",
       "      <td>489.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>67593</td>\n",
       "      <td>1092</td>\n",
       "      <td>4623.70</td>\n",
       "      <td>2564.2</td>\n",
       "      <td>337</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>3403.800</td>\n",
       "      <td>70</td>\n",
       "      <td>1525.200</td>\n",
       "      <td>1352.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133295</td>\n",
       "      <td>4630</td>\n",
       "      <td>6540.90</td>\n",
       "      <td>6400.7</td>\n",
       "      <td>795</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>2342.500</td>\n",
       "      <td>50</td>\n",
       "      <td>921.000</td>\n",
       "      <td>787.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98225</td>\n",
       "      <td>2616</td>\n",
       "      <td>5727.20</td>\n",
       "      <td>4157.8</td>\n",
       "      <td>621</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>2964.950</td>\n",
       "      <td>60</td>\n",
       "      <td>1499.050</td>\n",
       "      <td>1282.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>94603</td>\n",
       "      <td>2599</td>\n",
       "      <td>5276.10</td>\n",
       "      <td>4033.6</td>\n",
       "      <td>545</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>2438.500</td>\n",
       "      <td>50</td>\n",
       "      <td>1513.500</td>\n",
       "      <td>1165.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0   56744  1313      2922.51       2446.3              313   \n",
       "1                  0   67593  1092      4623.70       2564.2              337   \n",
       "2                  0  133295  4630      6540.90       6400.7              795   \n",
       "3                  0   98225  2616      5727.20       4157.8              621   \n",
       "4                  0   94603  2599      5276.10       4033.6              545   \n",
       "\n",
       "                 buy  sell     price  sale   bprofit   sprofit  \n",
       "current_bid_idx                                                 \n",
       "0                 52    42  2238.795    52  1106.005   489.295  \n",
       "1                 70    70  3403.800    70  1525.200  1352.400  \n",
       "2                 48    45  2342.500    50   921.000   787.300  \n",
       "3                 60    60  2964.950    60  1499.050  1282.950  \n",
       "4                 48    46  2438.500    50  1513.500  1165.600  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.tail(500).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.round_data.redemption_values.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf995d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.step_data.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9122b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_period(env.db, 0, 2236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "env.action_space = spaces.Discrete(51)\n",
    "#policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[64, 64]))\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1,)\n",
    "model.learn(50000, progress_bar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.step_data.head(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.step_data.tail(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de98f33",
   "metadata": {},
   "source": [
    "## ON POLICY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75639662",
   "metadata": {},
   "source": [
    "### DDPG - Deterministic Deep Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[64, 64]))\n",
    "model = DDPG(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1,)\n",
    "model.learn(50000, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9acec3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>562</td>\n",
       "      <td>1433.54</td>\n",
       "      <td>914.6</td>\n",
       "      <td>109</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1014.965</td>\n",
       "      <td>19</td>\n",
       "      <td>2.835</td>\n",
       "      <td>352.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>214</td>\n",
       "      <td>874.80</td>\n",
       "      <td>478.2</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>676.500</td>\n",
       "      <td>14</td>\n",
       "      <td>309.300</td>\n",
       "      <td>251.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>855</td>\n",
       "      <td>1262.00</td>\n",
       "      <td>1241.7</td>\n",
       "      <td>159</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>429.400</td>\n",
       "      <td>9</td>\n",
       "      <td>178.600</td>\n",
       "      <td>159.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>492</td>\n",
       "      <td>1080.60</td>\n",
       "      <td>774.7</td>\n",
       "      <td>118</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>600.700</td>\n",
       "      <td>12</td>\n",
       "      <td>292.100</td>\n",
       "      <td>257.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>327</td>\n",
       "      <td>839.20</td>\n",
       "      <td>572.6</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>498.950</td>\n",
       "      <td>10</td>\n",
       "      <td>291.450</td>\n",
       "      <td>195.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0      11   562      1433.54        914.6              109   \n",
       "1                  0       7   214       874.80        478.2               68   \n",
       "2                  0      12   855      1262.00       1241.7              159   \n",
       "3                  0      13   492      1080.60        774.7              118   \n",
       "4                  0       7   327       839.20        572.6               67   \n",
       "\n",
       "                 buy  sell     price  sale  bprofit  sprofit  \n",
       "current_bid_idx                                               \n",
       "0                 12    19  1014.965    19    2.835  352.065  \n",
       "1                 14    14   676.500    14  309.300  251.200  \n",
       "2                  8     8   429.400     9  178.600  159.800  \n",
       "3                 12    11   600.700    12  292.100  257.900  \n",
       "4                 10    10   498.950    10  291.450  195.850  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.head(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a34e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10857</td>\n",
       "      <td>269</td>\n",
       "      <td>506.15</td>\n",
       "      <td>514.1</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>432.865</td>\n",
       "      <td>10</td>\n",
       "      <td>162.835</td>\n",
       "      <td>56.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13579</td>\n",
       "      <td>239</td>\n",
       "      <td>946.20</td>\n",
       "      <td>548.3</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>709.250</td>\n",
       "      <td>14</td>\n",
       "      <td>276.550</td>\n",
       "      <td>278.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26237</td>\n",
       "      <td>899</td>\n",
       "      <td>1291.80</td>\n",
       "      <td>1228.7</td>\n",
       "      <td>169</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>505.900</td>\n",
       "      <td>11</td>\n",
       "      <td>197.900</td>\n",
       "      <td>146.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>22625</td>\n",
       "      <td>586</td>\n",
       "      <td>1247.20</td>\n",
       "      <td>936.0</td>\n",
       "      <td>142</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>609.450</td>\n",
       "      <td>13</td>\n",
       "      <td>335.850</td>\n",
       "      <td>278.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17194</td>\n",
       "      <td>457</td>\n",
       "      <td>1009.10</td>\n",
       "      <td>693.3</td>\n",
       "      <td>105</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>488.600</td>\n",
       "      <td>10</td>\n",
       "      <td>301.800</td>\n",
       "      <td>258.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0   10857   269       506.15        514.1               73   \n",
       "1                  0   13579   239       946.20        548.3               44   \n",
       "2                  0   26237   899      1291.80       1228.7              169   \n",
       "3                  0   22625   586      1247.20        936.0              142   \n",
       "4                  0   17194   457      1009.10        693.3              105   \n",
       "\n",
       "                 buy  sell    price  sale  bprofit  sprofit  \n",
       "current_bid_idx                                              \n",
       "0                 10     6  432.865    10  162.835   56.565  \n",
       "1                 14    14  709.250    14  276.550  278.950  \n",
       "2                 11     9  505.900    11  197.900  146.000  \n",
       "3                 13    13  609.450    13  335.850  278.750  \n",
       "4                  9    10  488.600    10  301.800  258.100  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.tail(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfc29c",
   "metadata": {},
   "source": [
    "### PPO - Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[64, 64]))\n",
    "model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(50000, progress_bar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbafb0",
   "metadata": {},
   "source": [
    "### A2C - Advantage Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc92acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A2C model\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "a2c_model = A2C(MlpPolicy, env, verbose=0)\n",
    "\n",
    "# Train the A2C agent for 10000 steps\n",
    "a2c_model.learn(total_timesteps=training_step, progress_bar = True)\n",
    "\n",
    "# Evaluate the trained A2C agent\n",
    "mean_reward_a2c, std_reward_a2c = evaluate_policy(a2c_model, env, n_eval_episodes=eval_steps)\n",
    "print(f\"A2C mean_reward: {mean_reward_a2c:.2f} +/- {std_reward_a2c:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e53392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
