{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550f025-6d76-440c-8602-baecfccdb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "from algorithms2 import * \n",
    "from agents import *\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "numRounds, numPeriods, numSteps = 1, 100, 1\n",
    "numBuyers, numSellers, numTokens = 1, 1, 5\n",
    "gameTypes, seed = '1001', 42\n",
    "disclosure = []\n",
    "depth = 0\n",
    "gameData = [gameTypes, numBuyers, numSellers, numTokens, numRounds, numPeriods, numSteps, seed]\n",
    "# ZeroIntelligence, TruthTeller\n",
    "buyers = [\n",
    "    Reinforcer(gameData, disclosure, index=0, buyer=1, reinforcer=1, numActions = 2),\n",
    "]\n",
    "sellers = [\n",
    "    TruthTeller(gameData, disclosure, index=0, buyer=0, reinforcer=0),\n",
    "          ]\n",
    "log = Log(gameData, disclosure)\n",
    "verbose = 10\n",
    "rnd = 0\n",
    "resetRounds(gameData, log, buyers, sellers, rnd)\n",
    "print(log.roundData.sellerCosts.item())\n",
    "print(log.roundData.buyerValues.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be5b7a-9b69-4a2c-84e4-cd8d1ed3f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rnd in range(numRounds):\n",
    "#    resetRounds(gameData, log, buyers, sellers, rnd)\n",
    "#    profits = []\n",
    "for period in range(numPeriods):\n",
    "    resetPeriods(buyers, sellers)\n",
    "    profits = []\n",
    "    for step in range(numSteps):\n",
    "        resetSteps(buyers, sellers)\n",
    "        bids, asks = collectOffers(buyers, sellers)\n",
    "        currentAsk, currentAskIdx, currentBid, currentBidIdx = bestOffers(bids, asks)\n",
    "        price, buy, sell = trade(buyers, sellers, currentAsk, currentAskIdx, currentBid, currentBidIdx)\n",
    "        \n",
    "        bprofit, sprofit = 0, 0\n",
    "        if price > 0:\n",
    "            buyers[currentBidIdx].transact(price)\n",
    "            sellers[currentAskIdx].transact(price)\n",
    "            bprofit = buyers[currentBidIdx].stepProfits\n",
    "            sprofit = sellers[currentAskIdx].stepProfits\n",
    "        profits.append(bprofit)\n",
    "        log.addStep([rnd, period, step, bids, asks, currentBid, currentBidIdx, currentAsk, currentAskIdx, buy, sell, price, price>0, bprofit, sprofit])\n",
    "        observe(buyers, sellers, log.disclose())\n",
    "        updateStates(buyers, sellers)\n",
    "    updatePolicy(buyers, sellers)\n",
    "    #if rnd%verbose==0:\n",
    "        #print(rnd, period, log.stepData[['currentBidIdx', 'bprofit']].tail(verbose).groupby('currentBidIdx').sum().values.reshape(-1,))\n",
    "        #print(rnd, period, bids[0], np.sum(profits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b013481-3395-4d04-9df3-ac97e30c2745",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'buyers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbuyers\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstate\n",
      "\u001b[0;31mNameError\u001b[0m: name 'buyers' is not defined"
     ]
    }
   ],
   "source": [
    "buyers[0].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40165dfb-e2f6-4cdf-96b0-ca8c92bcfd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.stepData.currentBid.max(), log.stepData.currentBid.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947af567-a4f4-4041-995d-8cddc4f2722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trackBuyersIdx = []\n",
    "type = 'period'\n",
    "trackSellersIdx = [0]\n",
    "rolling_window = 1\n",
    "df = log.stepData\n",
    "fig, ax = plt.subplots()\n",
    "colors = customGraphSettings()\n",
    "for j in range(numBuyers):\n",
    "    rolling_mean = df[df.currentBidIdx == j][[type, 'bprofit']].groupby([type]).sum().rolling(rolling_window).mean()\n",
    "    if j in trackBuyersIdx:\n",
    "        ax.plot(rolling_mean, color = 'red', alpha = 1.0, linestyle = 'dotted', label = f'Bidder {j}')\n",
    "    else:\n",
    "        ax.plot(rolling_mean, color = 'red', alpha = 0.3, linestyle = 'dotted')\n",
    "        \n",
    "for j in range(numSellers):\n",
    "    rolling_mean = df[df.currentAskIdx == j][[type, 'sprofit']].groupby([type]).sum().rolling(rolling_window).mean()\n",
    "    if j in trackSellersIdx:\n",
    "        ax.plot(rolling_mean, color = 'blue', alpha = 1.0, linestyle = 'dotted', label = f'Asker {j}')\n",
    "    else:\n",
    "        ax.plot(rolling_mean, color = 'blue', alpha = 0.3, linestyle = 'dotted')\n",
    "\n",
    "ax.set_title('Learning Curves', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Avg Profit')\n",
    "ax.yaxis.tick_left()\n",
    "ax.xaxis.tick_bottom()\n",
    "ax.xaxis.set_label_position('bottom')\n",
    "#ax.set_yticks(np.arange(0, 100, 5))\n",
    "#ax.set_xticks(np.arange(0, 100, 20))\n",
    "ax.text(0.80, 0.10, f'Round: {rnd}', transform=plt.gca().transAxes, alpha=0.5)\n",
    "ax.text(0.80, 0.05, f'Period: {period}', transform=plt.gca().transAxes, alpha=0.5)\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "plt.ylim(ymin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9f26c-de4d-4104-94fb-d29d2c0244b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24dbce-5d6e-4fc5-b4f4-591db452ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b958f0-0679-4cd7-9d55-7d7c4d6b3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.graphSales(0, 994, trackBuyersIdx=[], trackSellersIdx=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb390d6e-9f7f-4252-84fd-8a17c7063798",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.graphOffers(0, 994, [0], [0])\n",
    "log.graphSales(0, 994, trackBuyersIdx=[], trackSellersIdx=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182436b-ab75-4b82-ad06-f253ee994f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.graphOffers(0, 0, [0], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab1428-ded6-48c9-b06d-c97c6cf9c3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff24bd-5171-47a6-a5a9-fecdb3351790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12024e-7206-438b-88e3-098883a5b662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cda11-7e4a-42d1-901d-41ccedc92226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1a5b4-81f7-4cf1-95ce-cbf2de5a0852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239ade5-825b-42a1-bb13-b2fc48215070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541ecf1-45cc-45e4-a90e-bc4c3503ff10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb442c9-947b-40f2-ab6b-be624bcb5529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb476f6a-c590-4fd4-844d-98d4b2f8147d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47456d76-f518-41a9-886a-6ca481ae7f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7dccae-ba78-4706-bb09-0fed1afed4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf70173-fbf7-4595-9a2c-74ec59d4b3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01de14-f9be-4417-913e-3a663a9219f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9005f3-d381-41cf-b2f6-7559e625ad75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f500c8a-a14d-4260-a03a-ea28cbc97f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f010d8-4e21-47a8-878b-f602dcc32d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b54e1c-4b0d-471b-afab-f5fd3d8adb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3ebe4-1c3b-43d8-aa2b-7b0b3180e508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e733dd1-182f-4e2d-9a21-aab34c868b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bed9d-a279-4aa1-b0f7-37dccebd7c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c72d0-17b0-4ce0-8637-4f9bd4130489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d07a6-13fe-49ab-8455-8d23b1c01fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "\n",
    "# define policy network\n",
    "class policy_net(nn.Module):\n",
    "    def __init__(self, nS, nH, nA): # nS: state space size, nH: n. of neurons in hidden layer, nA: size action space\n",
    "        super(policy_net, self).__init__()\n",
    "        self.h = nn.Linear(nS, nH)\n",
    "        self.out = nn.Linear(nH, nA)\n",
    "\n",
    "    # define forward pass with one hidden layer with ReLU activation and sofmax after output layer\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h(x))\n",
    "        x = F.softmax(self.out(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# create environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "# instantiate the policy\n",
    "policy = policy_net(env.observation_space.shape[0], 20, env.action_space.n)\n",
    "# create an optimizer\n",
    "optimizer = torch.optim.Adam(policy.parameters())\n",
    "# initialize gamma and stats\n",
    "gamma=0.99\n",
    "n_episode = 1\n",
    "returns = deque(maxlen=100)\n",
    "render_rate = 100 # render every render_rate episodes\n",
    "\n",
    "while True:\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    states  = []\n",
    "    # reset environment\n",
    "    state, _ = env.reset()\n",
    "    print('state', state)\n",
    "    while True:\n",
    "        # render episode every render_rate epsiodes\n",
    "        if n_episode%render_rate==0:\n",
    "            env.render()\n",
    "\n",
    "        # calculate probabilities of taking each action\n",
    "        probs = policy(torch.tensor(state).unsqueeze(0).float())\n",
    "        print('probs', probs)\n",
    "\n",
    "        # sample an action from that set of probs\n",
    "        sampler = Categorical(probs)\n",
    "        action = sampler.sample()\n",
    "        print('action', action)\n",
    "\n",
    "        # use that action in the environment\n",
    "        new_state, reward, done, info, _ = env.step(action.item())\n",
    "        print('new_state', new_state)\n",
    "        print('reward', reward)\n",
    "        print('done', done)\n",
    "\n",
    "        # store state, action and reward\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        state = new_state\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # preprocess rewards\n",
    "    rewards = np.array(rewards)\n",
    "    # calculate rewards to go for less variance\n",
    "    batch_rewards = torch.tensor([np.sum(rewards[i:]*(gamma**np.array(range(i, len(rewards))))) for i in range(len(rewards))])\n",
    "    # or uncomment following line for normal rewards\n",
    "    print('rewards', rewards)\n",
    "    print('batch_rewards', batch_rewards)\n",
    "    print('alt', torch.sum(torch.tensor(rewards)))\n",
    "\n",
    "    # preprocess states and actions\n",
    "    batch_states = torch.tensor(states).float()\n",
    "    batch_actions = torch.tensor(actions)\n",
    "    print('batch_states', batch_states)\n",
    "    print('batch_actions', batch_actions)\n",
    "    \n",
    "    # calculate gradient\n",
    "    batch_probs = policy(batch_states)\n",
    "    print('batch_probs', batch_probs)\n",
    "    sampler = Categorical(batch_probs)\n",
    "    batch_log_probs = -sampler.log_prob(batch_actions)   # \"-\" because it was built to work with gradient descent, but we are using gradient ascent\n",
    "    print('batch_log_probs', batch_log_probs)\n",
    "\n",
    "    batch_loss = torch.sum(batch_log_probs * batch_rewards) # loss that when differentiated with autograd gives the gradient of J(θ)\n",
    "    print('batch_loss', batch_loss.item())\n",
    "    # update policy weights\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# close environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dcf904-4e9e-4e0f-8961-6057aabb6b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
