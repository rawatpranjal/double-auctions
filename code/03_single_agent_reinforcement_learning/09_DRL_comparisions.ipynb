{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b60ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action Space Type</th>\n",
       "      <th>Key Innovation</th>\n",
       "      <th>On - Off Policy</th>\n",
       "      <th>Value / Policy Based</th>\n",
       "      <th>Year of Publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REINFORCE</th>\n",
       "      <td>Both</td>\n",
       "      <td>Direct policy optimization with policy gradien...</td>\n",
       "      <td>On</td>\n",
       "      <td>Policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRPO</th>\n",
       "      <td>Both</td>\n",
       "      <td>Trust region optimization for stable learning....</td>\n",
       "      <td>On</td>\n",
       "      <td>Policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPO</th>\n",
       "      <td>Both</td>\n",
       "      <td>Clipped surrogate objective for stable learnin...</td>\n",
       "      <td>On</td>\n",
       "      <td>Policy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2C</th>\n",
       "      <td>Both</td>\n",
       "      <td>Combines actor and critic for efficient traini...</td>\n",
       "      <td>On</td>\n",
       "      <td>Both</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DQN</th>\n",
       "      <td>Discrete</td>\n",
       "      <td>Deep Q-network approximation of the Q-function...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Value</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDPG</th>\n",
       "      <td>Continuous</td>\n",
       "      <td>Continuous action space extension of DQN. Adap...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Both</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3C</th>\n",
       "      <td>Both</td>\n",
       "      <td>Asynchronous training of multiple agents. Para...</td>\n",
       "      <td>On</td>\n",
       "      <td>Both</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAC</th>\n",
       "      <td>Continuous</td>\n",
       "      <td>Entropy regularization for improved exploratio...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Both</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD3</th>\n",
       "      <td>Both</td>\n",
       "      <td>Twin critics and delayed policy updates. Intro...</td>\n",
       "      <td>On</td>\n",
       "      <td>Both</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4PG</th>\n",
       "      <td>Continuous</td>\n",
       "      <td>Distributional value estimation with determini...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Both</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-Learning</th>\n",
       "      <td>Discrete</td>\n",
       "      <td>Value iteration with Q-value updates. Introduc...</td>\n",
       "      <td>Off</td>\n",
       "      <td>Value</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Action Space Type  \\\n",
       "REINFORCE               Both   \n",
       "TRPO                    Both   \n",
       "PPO                     Both   \n",
       "A2C                     Both   \n",
       "DQN                 Discrete   \n",
       "DDPG              Continuous   \n",
       "A3C                     Both   \n",
       "SAC               Continuous   \n",
       "TD3                     Both   \n",
       "D4PG              Continuous   \n",
       "Q-Learning          Discrete   \n",
       "\n",
       "                                               Key Innovation On - Off Policy  \\\n",
       "REINFORCE   Direct policy optimization with policy gradien...              On   \n",
       "TRPO        Trust region optimization for stable learning....              On   \n",
       "PPO         Clipped surrogate objective for stable learnin...              On   \n",
       "A2C         Combines actor and critic for efficient traini...              On   \n",
       "DQN         Deep Q-network approximation of the Q-function...             Off   \n",
       "DDPG        Continuous action space extension of DQN. Adap...             Off   \n",
       "A3C         Asynchronous training of multiple agents. Para...              On   \n",
       "SAC         Entropy regularization for improved exploratio...             Off   \n",
       "TD3         Twin critics and delayed policy updates. Intro...              On   \n",
       "D4PG        Distributional value estimation with determini...             Off   \n",
       "Q-Learning  Value iteration with Q-value updates. Introduc...             Off   \n",
       "\n",
       "           Value / Policy Based Year of Publication  \n",
       "REINFORCE                Policy                None  \n",
       "TRPO                     Policy                None  \n",
       "PPO                      Policy                None  \n",
       "A2C                        Both                None  \n",
       "DQN                       Value                2015  \n",
       "DDPG                       Both                2016  \n",
       "A3C                        Both                2016  \n",
       "SAC                        Both                2018  \n",
       "TD3                        Both                2018  \n",
       "D4PG                       Both                2018  \n",
       "Q-Learning                Value                1957  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Action Space Type\": [\"Both\", \"Both\", \"Both\", \"Both\", \"Discrete\", \"Continuous\", \"Both\", \"Continuous\", \"Both\", \"Continuous\", \"Discrete\"],\n",
    "    \"Key Innovation\": [\n",
    "        \"Direct policy optimization with policy gradient. Introduced the idea of optimizing the policy directly using gradient ascent. Enabled learning in high-dimensional action spaces.\",\n",
    "        \"Trust region optimization for stable learning. Introduced trust region methods to stabilize policy updates and prevent large policy changes that could lead to divergence.\",\n",
    "        \"Clipped surrogate objective for stable learning. Addressed issues with trust region methods by using a clipped surrogate objective, ensuring monotonic improvement.\",\n",
    "        \"Combines actor and critic for efficient training. Utilizes both value and policy networks to improve sample efficiency and convergence speed.\",\n",
    "        \"Deep Q-network approximation of the Q-function. Introduced deep neural networks to approximate the Q-function, making it possible to handle high-dimensional state spaces.\",\n",
    "        \"Continuous action space extension of DQN. Adapted DQN for continuous action spaces using actor-critic architecture and deterministic policy gradients.\",\n",
    "        \"Asynchronous training of multiple agents. Parallelizes training by having multiple agents interact with their environments asynchronously, improving data efficiency.\",\n",
    "        \"Entropy regularization for improved exploration. Encourages exploration by adding an entropy term to the objective function, balancing exploration and exploitation.\",\n",
    "        \"Twin critics and delayed policy updates. Introduced twin Q-networks to improve stability and utilized delayed policy updates for better performance.\",\n",
    "        \"Distributional value estimation with deterministic policy gradients. Estimated value distributions instead of single values and combined them with deterministic policy gradients for improved learning.\",\n",
    "        \"Value iteration with Q-value updates. Introduced the concept of Q-values and iteratively updates Q-values using the Bellman equation for value estimation.\"\n",
    "    ],\n",
    "    \"On - Off Policy\": [\"On\", \"On\", \"On\", \"On\", \"Off\", \"Off\", \"On\", \"Off\", \"On\", \"Off\", \"Off\"],\n",
    "    \"Value / Policy Based\": [\"Policy\", \"Policy\", \"Policy\", \"Both\", \"Value\", \"Both\", \"Both\", \"Both\", \"Both\", \"Both\", \"Value\"],\n",
    "    \"Year of Publication\": [None, None, None, None, \"2015\", \"2016\", \"2016\", \"2018\", \"2018\", \"2018\", \"1957\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=[\"REINFORCE\", \"TRPO\", \"PPO\", \"A2C\", \"DQN\", \"DDPG\", \"A3C\", \"SAC\", \"TD3\", \"D4PG\", \"Q-Learning\"])\n",
    "\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ce0ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from functions import *\n",
    "from itertools import count\n",
    "buyer_strategies = ['Honest', 'Random', 'Random', 'Random']\n",
    "seller_strategies = ['Honest', 'Honest', 'Honest', 'Honest', 'Honest','Honest', 'Honest', 'Honest', 'Honest', 'Honest']\n",
    "nbuyers, nsellers = len(buyer_strategies), len(seller_strategies)\n",
    "nrounds, nperiods, ntokens, nsteps, gametype, nbuyers, nsellers = 10, 10, 8, 30, '1234', len(buyer_strategies), len(seller_strategies)\n",
    "R1, R2, R3, R4 = gametype_to_ran(gametype)\n",
    "game_metadata = [nrounds, nperiods, ntokens, nbuyers, nsellers, nsteps, R1, R2, R3, R4]\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "rnd = 0\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "period = 0\n",
    "num_states = nsteps\n",
    "min_frac = 0.01\n",
    "max_frac = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87aeeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, db, nsteps, render_mode = None):\n",
    "        self.rnd = 0\n",
    "        self.period = -1\n",
    "        self.nperiods = nperiods\n",
    "        self.db = db\n",
    "        self.action_space = spaces.Box(0,1,(1,),dtype=np.float)\n",
    "        self.observation_space = spaces.Box(0,nsteps,(1,),dtype=np.float)\n",
    "\n",
    "    def reset(self,seed=None):\n",
    "        #self.db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "        self.db.reset_period(self.rnd)\n",
    "        self.timestep = 0\n",
    "        self.period += 1\n",
    "        observation = np.array([0])\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action, seed=None, options=None):\n",
    "        [buyer.next_token() for buyer in self.db.buyers]\n",
    "        [seller.next_token() for seller in self.db.sellers]\n",
    "        bid_frac = action.item()\n",
    "        # convert action to bid\n",
    "        self.db.buyers[0].next_token()\n",
    "        min_bid = self.db.buyers[0].value * min_frac\n",
    "        max_bid = self.db.buyers[0].value * max_frac\n",
    "        bid = np.round(max_bid * bid_frac + (1 - bid_frac) * min_bid, 2)\n",
    "\n",
    "        # simulate market\n",
    "        bids = [buyer.bid(self.db) for buyer in self.db.buyers]\n",
    "        bids[0] = bid\n",
    "        asks = [seller.ask(self.db) for seller in self.db.sellers]\n",
    "        current_ask, current_ask_idx, current_bid, current_bid_idx = current_bid_ask(bids, asks)\n",
    "        sale, price, bprofit, sprofit, buy, sell = buy_sell(self.db, current_bid, current_bid_idx, current_ask, current_ask_idx)\n",
    "        step_data = [self.rnd, self.period, self.timestep, bids, asks, current_bid, current_bid_idx, current_ask, current_ask_idx, buy, sell, price, sale, bprofit, sprofit]\n",
    "        self.db.add_step(step_data)\n",
    "\n",
    "        # compute reward, new state\n",
    "        reward = 0.0\n",
    "        if sale == 1 and current_bid_idx == 0:\n",
    "            reward = bprofit\n",
    "        observation = np.array([self.timestep + 1])\n",
    "\n",
    "        # check termination\n",
    "        self.timestep += 1\n",
    "        if self.timestep == nsteps:\n",
    "            terminated = True\n",
    "            self.timestep = 0\n",
    "        else:\n",
    "            terminated = False\n",
    "        infos = {\"TimeLimit.truncated\":True}\n",
    "        truncated = False\n",
    "        return observation, reward, terminated, truncated, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "313e5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56d7618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = 0\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "observation, info = env.reset()\n",
    "for period in count():\n",
    "    for timestep in count(): \n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info, _ = env.step(action)\n",
    "        #print(f\"Rnd: {rnd}, Period: {period}, New State: {observation}, Action:{np.round(action,1)}, Reward: {np.round(reward,1)}, Period End: {done}\")\n",
    "        if done:\n",
    "            # If the episode is done, reset the environment\n",
    "            #print('done')\n",
    "            observation, info = env.reset()\n",
    "            break\n",
    "    if period == nperiods:\n",
    "        period = 0\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8540088f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>435</td>\n",
       "      <td>1814.99</td>\n",
       "      <td>1157.7</td>\n",
       "      <td>157</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>1430.115</td>\n",
       "      <td>33</td>\n",
       "      <td>695.085</td>\n",
       "      <td>354.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>1857</td>\n",
       "      <td>4670.10</td>\n",
       "      <td>3891.7</td>\n",
       "      <td>565</td>\n",
       "      <td>66</td>\n",
       "      <td>51</td>\n",
       "      <td>2799.550</td>\n",
       "      <td>66</td>\n",
       "      <td>1016.350</td>\n",
       "      <td>594.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>1480</td>\n",
       "      <td>5376.20</td>\n",
       "      <td>3386.1</td>\n",
       "      <td>573</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>2648.800</td>\n",
       "      <td>56</td>\n",
       "      <td>1758.400</td>\n",
       "      <td>1149.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>439</td>\n",
       "      <td>1013</td>\n",
       "      <td>4896.80</td>\n",
       "      <td>2661.7</td>\n",
       "      <td>368</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>3065.600</td>\n",
       "      <td>66</td>\n",
       "      <td>1977.900</td>\n",
       "      <td>1223.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0     166   435      1814.99       1157.7              157   \n",
       "1                  0     549  1857      4670.10       3891.7              565   \n",
       "2                  0     496  1480      5376.20       3386.1              573   \n",
       "3                  0     439  1013      4896.80       2661.7              368   \n",
       "\n",
       "                 buy  sell     price  sale   bprofit   sprofit  \n",
       "current_bid_idx                                                 \n",
       "0                 33    29  1430.115    33   695.085   354.215  \n",
       "1                 66    51  2799.550    66  1016.350   594.350  \n",
       "2                 56    55  2648.800    56  1758.400  1149.500  \n",
       "3                 66    66  3065.600    66  1977.900  1223.800  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.head(1000).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef7b34a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define your environment and parameters (replace with your actual environment setup)\n",
    "rnd = 0\n",
    "period = 0\n",
    "num_states = nsteps\n",
    "min_frac = 0.01\n",
    "max_frac = 1.5\n",
    "eval_steps = 1000\n",
    "training_step = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29040eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO, A2C, DQN, SAC\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad71ec",
   "metadata": {},
   "source": [
    "### Continous Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e856dcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using cpu device\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using cpu device\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Wrapping the env with a `Monitor` wrapper\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Wrapping the env with a `Monitor` wrapper\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Wrapping the env in a DummyVecEnv.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Wrapping the env in a DummyVecEnv.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "LiveError",
     "evalue": "Only one live display may be active at once",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLiveError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m policy_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(net_arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(pi\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m], qf\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m]))\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m SAC(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/sac/sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[1;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:309\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[1;32m    294\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOffPolicyAlgorithm:\n\u001b[1;32m    301\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_learn(\n\u001b[1;32m    302\u001b[0m         total_timesteps,\n\u001b[1;32m    303\u001b[0m         callback,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m         progress_bar,\n\u001b[1;32m    307\u001b[0m     )\n\u001b[0;32m--> 309\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m    312\u001b[0m         rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_rollouts(\n\u001b[1;32m    313\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv,\n\u001b[1;32m    314\u001b[0m             train_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m             log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[1;32m    320\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:74\u001b[0m, in \u001b[0;36mBaseCallback.on_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Update num_timesteps in case training was done before\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:198\u001b[0m, in \u001b[0;36mCallbackList._on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_training_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 198\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:74\u001b[0m, in \u001b[0;36mBaseCallback.on_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Update num_timesteps in case training was done before\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:682\u001b[0m, in \u001b[0;36mProgressBarCallback._on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_training_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;66;03m# Initialize progress bar\u001b[39;00m\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;66;03m# Remove timesteps that were done in previous training sessions\u001b[39;00m\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_timesteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_timesteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tqdm/rich.py:116\u001b[0m, in \u001b[0;36mtqdm_rich.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m options\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleave)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prog \u001b[38;5;241m=\u001b[39m Progress(\u001b[38;5;241m*\u001b[39mprogress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prog\u001b[38;5;241m.\u001b[39madd_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/rich/progress.py:1161\u001b[0m, in \u001b[0;36mProgress.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgress\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1161\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/rich/progress.py:1152\u001b[0m, in \u001b[0;36mProgress.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;124;03m\"\"\"Start the progress display.\"\"\"\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/rich/live.py:113\u001b[0m, in \u001b[0;36mLive.start\u001b[0;34m(self, refresh)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_live\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_screen:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/rich/console.py:809\u001b[0m, in \u001b[0;36mConsole.set_live\u001b[0;34m(self, live)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mLiveError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one live display may be active at once\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;241m=\u001b[39m live\n",
      "\u001b[0;31mLiveError\u001b[0m: Only one live display may be active at once"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import SAC, DDPG, TD3, A2C, PPO\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "policy_kwargs = dict(net_arch=dict(pi=[128, 128], qf=[128, 128]))\n",
    "model = SAC(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1,)\n",
    "model.learn(50000, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.step_data.head(16).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52b6bcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.tail(16).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d8e20f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.6,  48.9,  35.3,  18.7],\n",
       "       [ 79. ,  66.7,  46.6,  34. ],\n",
       "       [ 92.3,  60.3,  36.8,  24.1],\n",
       "       [106.1,  79.4,  63.3,  35.9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.round_data.redemption_values.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bf995d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>bids</th>\n",
       "      <th>asks</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[77.1, 66.7, 68.8, 60.4]</td>\n",
       "      <td>[85.7, 47.5, 34.1, 49.4, 40.3, 36.4, 59.8, 50....</td>\n",
       "      <td>77.10</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>52.30</td>\n",
       "      <td>1</td>\n",
       "      <td>7.30</td>\n",
       "      <td>24.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[41.28, 63.9, 76.3, 56.4]</td>\n",
       "      <td>[85.7, 47.5, 34.1, 49.4, 40.3, 36.4, 59.8, 50....</td>\n",
       "      <td>76.30</td>\n",
       "      <td>2</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>55.20</td>\n",
       "      <td>1</td>\n",
       "      <td>37.10</td>\n",
       "      <td>21.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[60.79, 70.7, 57.7, 55.4]</td>\n",
       "      <td>[85.7, 47.5, 69.5, 49.4, 40.3, 36.4, 59.8, 50....</td>\n",
       "      <td>70.70</td>\n",
       "      <td>1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>53.55</td>\n",
       "      <td>1</td>\n",
       "      <td>25.45</td>\n",
       "      <td>17.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[37.68, 59.5, 59.0, 65.7]</td>\n",
       "      <td>[85.7, 47.5, 69.5, 49.4, 40.3, 83.3, 59.8, 50....</td>\n",
       "      <td>65.70</td>\n",
       "      <td>3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>53.00</td>\n",
       "      <td>1</td>\n",
       "      <td>53.10</td>\n",
       "      <td>12.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[45.1, 35.3, 43.1, 64.3]</td>\n",
       "      <td>[85.7, 47.5, 69.5, 49.4, 80.9, 83.3, 59.8, 50....</td>\n",
       "      <td>64.30</td>\n",
       "      <td>3</td>\n",
       "      <td>45.8</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>55.05</td>\n",
       "      <td>1</td>\n",
       "      <td>24.35</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[69.72, 64.2, 44.1, 33.8]</td>\n",
       "      <td>[85.7, 47.5, 69.5, 49.4, 80.9, 83.3, 59.8, 50....</td>\n",
       "      <td>69.72</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>58.61</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.71</td>\n",
       "      <td>11.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[12.93, 36.2, 38.5, 57.9]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 49.4, 80.9, 83.3, 59.8, 50....</td>\n",
       "      <td>57.90</td>\n",
       "      <td>3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>53.65</td>\n",
       "      <td>1</td>\n",
       "      <td>9.65</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[28.59, 57.1, 57.8, 31.2]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 50....</td>\n",
       "      <td>57.80</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>53.90</td>\n",
       "      <td>1</td>\n",
       "      <td>6.40</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[19.5, 66.5, 32.0, 30.0]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>66.50</td>\n",
       "      <td>1</td>\n",
       "      <td>59.2</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>62.85</td>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[35.85, 39.7, 25.0, 25.3]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>39.70</td>\n",
       "      <td>1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[4.83, 41.5, 28.6, 27.1]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>41.50</td>\n",
       "      <td>1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[46.83, 46.4, 36.7, 27.7]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>46.83</td>\n",
       "      <td>0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>[36.35, 35.5, 23.5, 33.2]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[15.6, 46.3, 18.5, 32.0]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>46.30</td>\n",
       "      <td>1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[18.63, 43.4, 18.5, 28.5]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>43.40</td>\n",
       "      <td>1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[21.51, 40.3, 28.5, 25.4]</td>\n",
       "      <td>[85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....</td>\n",
       "      <td>40.30</td>\n",
       "      <td>1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rnd  period  step                       bids  \\\n",
       "0     0       0     0   [77.1, 66.7, 68.8, 60.4]   \n",
       "1     0       0     1  [41.28, 63.9, 76.3, 56.4]   \n",
       "2     0       0     2  [60.79, 70.7, 57.7, 55.4]   \n",
       "3     0       0     3  [37.68, 59.5, 59.0, 65.7]   \n",
       "4     0       0     4   [45.1, 35.3, 43.1, 64.3]   \n",
       "5     0       0     5  [69.72, 64.2, 44.1, 33.8]   \n",
       "6     0       0     6  [12.93, 36.2, 38.5, 57.9]   \n",
       "7     0       0     7  [28.59, 57.1, 57.8, 31.2]   \n",
       "8     0       0     8   [19.5, 66.5, 32.0, 30.0]   \n",
       "9     0       0     9  [35.85, 39.7, 25.0, 25.3]   \n",
       "10    0       0    10   [4.83, 41.5, 28.6, 27.1]   \n",
       "11    0       0    11  [46.83, 46.4, 36.7, 27.7]   \n",
       "12    0       0    12  [36.35, 35.5, 23.5, 33.2]   \n",
       "13    0       0    13   [15.6, 46.3, 18.5, 32.0]   \n",
       "14    0       0    14  [18.63, 43.4, 18.5, 28.5]   \n",
       "15    0       0    15  [21.51, 40.3, 28.5, 25.4]   \n",
       "\n",
       "                                                 asks  current_bid  \\\n",
       "0   [85.7, 47.5, 34.1, 49.4, 40.3, 36.4, 59.8, 50....        77.10   \n",
       "1   [85.7, 47.5, 34.1, 49.4, 40.3, 36.4, 59.8, 50....        76.30   \n",
       "2   [85.7, 47.5, 69.5, 49.4, 40.3, 36.4, 59.8, 50....        70.70   \n",
       "3   [85.7, 47.5, 69.5, 49.4, 40.3, 83.3, 59.8, 50....        65.70   \n",
       "4   [85.7, 47.5, 69.5, 49.4, 80.9, 83.3, 59.8, 50....        64.30   \n",
       "5   [85.7, 47.5, 69.5, 49.4, 80.9, 83.3, 59.8, 50....        69.72   \n",
       "6   [85.7, 79.5, 69.5, 49.4, 80.9, 83.3, 59.8, 50....        57.90   \n",
       "7   [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 50....        57.80   \n",
       "8   [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        66.50   \n",
       "9   [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        39.70   \n",
       "10  [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        41.50   \n",
       "11  [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        46.83   \n",
       "12  [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        36.35   \n",
       "13  [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        46.30   \n",
       "14  [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        43.40   \n",
       "15  [85.7, 79.5, 69.5, 61.1, 80.9, 83.3, 59.8, 62....        40.30   \n",
       "\n",
       "    current_bid_idx  current_ask  current_ask_idx    buy   sell  price  sale  \\\n",
       "0                 0         27.5                9   True   True  52.30     1   \n",
       "1                 2         34.1                2   True   True  55.20     1   \n",
       "2                 1         36.4                5   True   True  53.55     1   \n",
       "3                 3         40.3                4   True   True  53.00     1   \n",
       "4                 3         45.8                9   True   True  55.05     1   \n",
       "5                 0         47.5                1   True   True  58.61     1   \n",
       "6                 3         49.4                3   True   True  53.65     1   \n",
       "7                 2         50.0                7   True   True  53.90     1   \n",
       "8                 1         59.2                8   True   True  62.85     1   \n",
       "9                 1         59.8                6  False  False    NaN     0   \n",
       "10                1         59.8                6  False  False    NaN     0   \n",
       "11                0         59.8                6  False  False    NaN     0   \n",
       "12                0         59.8                6  False  False    NaN     0   \n",
       "13                1         59.8                6  False  False    NaN     0   \n",
       "14                1         59.8                6  False  False    NaN     0   \n",
       "15                1         59.8                6  False  False    NaN     0   \n",
       "\n",
       "    bprofit  sprofit  \n",
       "0      7.30    24.80  \n",
       "1     37.10    21.10  \n",
       "2     25.45    17.15  \n",
       "3     53.10    12.70  \n",
       "4     24.35     9.25  \n",
       "5     -9.71    11.11  \n",
       "6      9.65     4.25  \n",
       "7      6.40     3.90  \n",
       "8      3.85     3.65  \n",
       "9      0.00     0.00  \n",
       "10     0.00     0.00  \n",
       "11     0.00     0.00  \n",
       "12     0.00     0.00  \n",
       "13     0.00     0.00  \n",
       "14     0.00     0.00  \n",
       "15     0.00     0.00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eaf961",
   "metadata": {},
   "source": [
    "### Discrete Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "368e8ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.13e+03 |\n",
      "|    exploration_rate | 0.988     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 169       |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total_timesteps  | 64        |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.58e+03 |\n",
      "|    exploration_rate | 0.976     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 182       |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total_timesteps  | 128       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.43e+03 |\n",
      "|    exploration_rate | 0.964     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 183       |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 192       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.47e+03 |\n",
      "|    exploration_rate | 0.951     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 185       |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 256       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.42e+03 |\n",
      "|    exploration_rate | 0.939     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 186       |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 320       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.56e+03 |\n",
      "|    exploration_rate | 0.927     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 185       |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 384       |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.6e+03 |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 186      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 448      |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.63e+03 |\n",
      "|    exploration_rate | 0.903     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 181       |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 512       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.63e+03 |\n",
      "|    exploration_rate | 0.891     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 178       |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 576       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.67e+03 |\n",
      "|    exploration_rate | 0.878     |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 173       |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 640       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.65e+03 |\n",
      "|    exploration_rate | 0.866     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 172       |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total_timesteps  | 704       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.62e+03 |\n",
      "|    exploration_rate | 0.854     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 172       |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total_timesteps  | 768       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.63e+03 |\n",
      "|    exploration_rate | 0.842     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 173       |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total_timesteps  | 832       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.61e+03 |\n",
      "|    exploration_rate | 0.83      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 169       |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total_timesteps  | 896       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.61e+03 |\n",
      "|    exploration_rate | 0.818     |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 171       |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total_timesteps  | 960       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.62e+03 |\n",
      "|    exploration_rate | 0.805     |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 172       |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total_timesteps  | 1024      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.63e+03 |\n",
      "|    exploration_rate | 0.793     |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 172       |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 1088      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.64e+03 |\n",
      "|    exploration_rate | 0.781     |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 172       |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 1152      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.63e+03 |\n",
      "|    exploration_rate | 0.769     |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 173       |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 1216      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.62e+03 |\n",
      "|    exploration_rate | 0.757     |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 171       |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 1280      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.6e+03 |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 171      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 1344     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.63e+03 |\n",
      "|    exploration_rate | 0.732     |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 171       |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 1408      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.66e+03 |\n",
      "|    exploration_rate | 0.72      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 171       |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 1472      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.68e+03 |\n",
      "|    exploration_rate | 0.708     |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 169       |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total_timesteps  | 1536      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.69e+03 |\n",
      "|    exploration_rate | 0.696     |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 169       |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total_timesteps  | 1600      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.72e+03 |\n",
      "|    exploration_rate | 0.684     |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 168       |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total_timesteps  | 1664      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.73e+03 |\n",
      "|    exploration_rate | 0.672     |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 169       |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total_timesteps  | 1728      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.71e+03 |\n",
      "|    exploration_rate | 0.66      |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 168       |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total_timesteps  | 1792      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.71e+03 |\n",
      "|    exploration_rate | 0.647     |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 168       |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 1856      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.635     |\n",
      "| time/               |           |\n",
      "|    episodes         | 120       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 1920      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.623     |\n",
      "| time/               |           |\n",
      "|    episodes         | 124       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 1984      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.611     |\n",
      "| time/               |           |\n",
      "|    episodes         | 128       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 2048      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.76e+03 |\n",
      "|    exploration_rate | 0.599     |\n",
      "| time/               |           |\n",
      "|    episodes         | 132       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 2112      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.76e+03 |\n",
      "|    exploration_rate | 0.587     |\n",
      "| time/               |           |\n",
      "|    episodes         | 136       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 2176      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.76e+03 |\n",
      "|    exploration_rate | 0.574     |\n",
      "| time/               |           |\n",
      "|    episodes         | 140       |\n",
      "|    fps              | 168       |\n",
      "|    time_elapsed     | 13        |\n",
      "|    total_timesteps  | 2240      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.562     |\n",
      "| time/               |           |\n",
      "|    episodes         | 144       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 13        |\n",
      "|    total_timesteps  | 2304      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.79e+03 |\n",
      "|    exploration_rate | 0.55      |\n",
      "| time/               |           |\n",
      "|    episodes         | 148       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 2368      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.76e+03 |\n",
      "|    exploration_rate | 0.538     |\n",
      "| time/               |           |\n",
      "|    episodes         | 152       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 2432      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.78e+03 |\n",
      "|    exploration_rate | 0.526     |\n",
      "| time/               |           |\n",
      "|    episodes         | 156       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total_timesteps  | 2496      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.78e+03 |\n",
      "|    exploration_rate | 0.514     |\n",
      "| time/               |           |\n",
      "|    episodes         | 160       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total_timesteps  | 2560      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.78e+03 |\n",
      "|    exploration_rate | 0.501     |\n",
      "| time/               |           |\n",
      "|    episodes         | 164       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total_timesteps  | 2624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.489     |\n",
      "| time/               |           |\n",
      "|    episodes         | 168       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 2688      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.477     |\n",
      "| time/               |           |\n",
      "|    episodes         | 172       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 2752      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.465     |\n",
      "| time/               |           |\n",
      "|    episodes         | 176       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 2816      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.78e+03 |\n",
      "|    exploration_rate | 0.453     |\n",
      "| time/               |           |\n",
      "|    episodes         | 180       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 2880      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.83e+03 |\n",
      "|    exploration_rate | 0.441     |\n",
      "| time/               |           |\n",
      "|    episodes         | 184       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 2944      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.428     |\n",
      "| time/               |           |\n",
      "|    episodes         | 188       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total_timesteps  | 3008      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.71e+03 |\n",
      "|    exploration_rate | 0.416     |\n",
      "| time/               |           |\n",
      "|    episodes         | 192       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total_timesteps  | 3072      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.7e+03 |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 165      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 3136     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.68e+03 |\n",
      "|    exploration_rate | 0.392     |\n",
      "| time/               |           |\n",
      "|    episodes         | 200       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total_timesteps  | 3200      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.7e+03 |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 166      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 3264     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.71e+03 |\n",
      "|    exploration_rate | 0.368     |\n",
      "| time/               |           |\n",
      "|    episodes         | 208       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total_timesteps  | 3328      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.356     |\n",
      "| time/               |           |\n",
      "|    episodes         | 212       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total_timesteps  | 3392      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.78e+03 |\n",
      "|    exploration_rate | 0.343     |\n",
      "| time/               |           |\n",
      "|    episodes         | 216       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total_timesteps  | 3456      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.73e+03 |\n",
      "|    exploration_rate | 0.331     |\n",
      "| time/               |           |\n",
      "|    episodes         | 220       |\n",
      "|    fps              | 167       |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total_timesteps  | 3520      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.73e+03 |\n",
      "|    exploration_rate | 0.319     |\n",
      "| time/               |           |\n",
      "|    episodes         | 224       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total_timesteps  | 3584      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.307     |\n",
      "| time/               |           |\n",
      "|    episodes         | 228       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total_timesteps  | 3648      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.295     |\n",
      "| time/               |           |\n",
      "|    episodes         | 232       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total_timesteps  | 3712      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.72e+03 |\n",
      "|    exploration_rate | 0.283     |\n",
      "| time/               |           |\n",
      "|    episodes         | 236       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total_timesteps  | 3776      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.27      |\n",
      "| time/               |           |\n",
      "|    episodes         | 240       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 3840      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.258     |\n",
      "| time/               |           |\n",
      "|    episodes         | 244       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 3904      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.246     |\n",
      "| time/               |           |\n",
      "|    episodes         | 248       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 3968      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.234     |\n",
      "| time/               |           |\n",
      "|    episodes         | 252       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 24        |\n",
      "|    total_timesteps  | 4032      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.79e+03 |\n",
      "|    exploration_rate | 0.222     |\n",
      "| time/               |           |\n",
      "|    episodes         | 256       |\n",
      "|    fps              | 166       |\n",
      "|    time_elapsed     | 24        |\n",
      "|    total_timesteps  | 4096      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.8e+03 |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 165      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 4160     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.8e+03 |\n",
      "|    exploration_rate | 0.197    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 165      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 4224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.8e+03 |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 165      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 4288     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.79e+03 |\n",
      "|    exploration_rate | 0.173     |\n",
      "| time/               |           |\n",
      "|    episodes         | 272       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 26        |\n",
      "|    total_timesteps  | 4352      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.81e+03 |\n",
      "|    exploration_rate | 0.161     |\n",
      "| time/               |           |\n",
      "|    episodes         | 276       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 26        |\n",
      "|    total_timesteps  | 4416      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.81e+03 |\n",
      "|    exploration_rate | 0.149     |\n",
      "| time/               |           |\n",
      "|    episodes         | 280       |\n",
      "|    fps              | 165       |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total_timesteps  | 4480      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.81e+03 |\n",
      "|    exploration_rate | 0.137     |\n",
      "| time/               |           |\n",
      "|    episodes         | 284       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total_timesteps  | 4544      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.85e+03 |\n",
      "|    exploration_rate | 0.124     |\n",
      "| time/               |           |\n",
      "|    episodes         | 288       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total_timesteps  | 4608      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.86e+03 |\n",
      "|    exploration_rate | 0.112     |\n",
      "| time/               |           |\n",
      "|    episodes         | 292       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 28        |\n",
      "|    total_timesteps  | 4672      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.86e+03 |\n",
      "|    exploration_rate | 0.1       |\n",
      "| time/               |           |\n",
      "|    episodes         | 296       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 28        |\n",
      "|    total_timesteps  | 4736      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.89e+03 |\n",
      "|    exploration_rate | 0.088     |\n",
      "| time/               |           |\n",
      "|    episodes         | 300       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total_timesteps  | 4800      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.91e+03 |\n",
      "|    exploration_rate | 0.0758    |\n",
      "| time/               |           |\n",
      "|    episodes         | 304       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total_timesteps  | 4864      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.87e+03 |\n",
      "|    exploration_rate | 0.0637    |\n",
      "| time/               |           |\n",
      "|    episodes         | 308       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total_timesteps  | 4928      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.88e+03 |\n",
      "|    exploration_rate | 0.0515    |\n",
      "| time/               |           |\n",
      "|    episodes         | 312       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total_timesteps  | 4992      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.85e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 316       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total_timesteps  | 5056      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.84e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 320       |\n",
      "|    fps              | 164       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total_timesteps  | 5120      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.8e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 163      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 5184     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 328       |\n",
      "|    fps              | 163       |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total_timesteps  | 5248      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.74e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 332       |\n",
      "|    fps              | 163       |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total_timesteps  | 5312      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.79e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 336       |\n",
      "|    fps              | 163       |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total_timesteps  | 5376      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 340       |\n",
      "|    fps              | 163       |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total_timesteps  | 5440      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 344       |\n",
      "|    fps              | 162       |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total_timesteps  | 5504      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.76e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 348       |\n",
      "|    fps              | 163       |\n",
      "|    time_elapsed     | 34        |\n",
      "|    total_timesteps  | 5568      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -2.8e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 162      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 5632     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 356       |\n",
      "|    fps              | 162       |\n",
      "|    time_elapsed     | 34        |\n",
      "|    total_timesteps  | 5696      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.76e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 360       |\n",
      "|    fps              | 162       |\n",
      "|    time_elapsed     | 35        |\n",
      "|    total_timesteps  | 5760      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.74e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 364       |\n",
      "|    fps              | 162       |\n",
      "|    time_elapsed     | 35        |\n",
      "|    total_timesteps  | 5824      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.75e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 368       |\n",
      "|    fps              | 162       |\n",
      "|    time_elapsed     | 36        |\n",
      "|    total_timesteps  | 5888      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 372       |\n",
      "|    fps              | 162       |\n",
      "|    time_elapsed     | 36        |\n",
      "|    total_timesteps  | 5952      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 16        |\n",
      "|    ep_rew_mean      | -2.77e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 376       |\n",
      "|    fps              | 162       |\n",
      "|    time_elapsed     | 37        |\n",
      "|    total_timesteps  | 6016      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[64, 64]))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m DQN(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[1;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:312\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 312\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:544\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    541\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    547\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:70\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m---> 70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [68], line 12\u001b[0m, in \u001b[0;36mTradingEnv.reset\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m,seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#self.db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_period\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperiod \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/AI_Double_Auctions/code/3_deep_reinforcement_learning/functions.py:159\u001b[0m, in \u001b[0;36mDatabase.reset_period\u001b[0;34m(self, rnd)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_period\u001b[39m(\u001b[38;5;28mself\u001b[39m, rnd):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnbuyers):\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuyers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsellers):\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msellers[i]\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;28mself\u001b[39m, rnd)\n",
      "File \u001b[0;32m~/Desktop/AI_Double_Auctions/code/3_deep_reinforcement_learning/functions.py:181\u001b[0m, in \u001b[0;36mTrader.reset\u001b[0;34m(self, db, rnd)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, db, rnd):\n\u001b[0;32m--> 181\u001b[0m     round_data \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_tokens_traded \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuyer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/AI_Double_Auctions/code/3_deep_reinforcement_learning/functions.py:170\u001b[0m, in \u001b[0;36mDatabase.get_round\u001b[0;34m(self, rnd)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_round\u001b[39m(\u001b[38;5;28mself\u001b[39m, rnd):\n\u001b[0;32m--> 170\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    171\u001b[0m     temp \u001b[38;5;241m=\u001b[39m temp[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrnd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupply_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_grid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredemption_values\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_costs\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_eqbm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq_eqbm\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m temp\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:3795\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3795\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3797\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:3850\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3848\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[1;32m   3849\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 3850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py:3904\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3902\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   3903\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m-> 3904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequals\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   3905\u001b[0m     result\u001b[38;5;241m.\u001b[39m_set_is_copy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   3906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:5590\u001b[0m, in \u001b[0;36mIndex.equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_extension_array_dtype(other\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   5587\u001b[0m     \u001b[38;5;66;03m# All EA-backed Index subclasses override equals\u001b[39;00m\n\u001b[1;32m   5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m other\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 5590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_equivalent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:549\u001b[0m, in \u001b[0;36marray_equivalent\u001b[0;34m(left, right, strict_nan, dtype_equal)\u001b[0m\n\u001b[1;32m    545\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# if we have structured dtypes, compare first\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 549\u001b[0m     left\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvoid \u001b[38;5;129;01mor\u001b[39;00m right\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvoid\n\u001b[1;32m    550\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m right\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(left, right)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "env.action_space = spaces.Discrete(31)\n",
    "#policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[64, 64]))\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1,)\n",
    "model.learn(50000, progress_bar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7027bbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.head(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d5a210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.tail(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de98f33",
   "metadata": {},
   "source": [
    "## ON POLICY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75639662",
   "metadata": {},
   "source": [
    "### DDPG - Deterministic Deep Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efbf2bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2daaf0a6764c3d85632b9ca4b00659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16       |\n",
      "|    ep_rew_mean     | 153      |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 64       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [76], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m policy_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(net_arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(pi\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m], qf\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m]))\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m DDPG(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/ddpg/ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[1;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[1;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:331\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:188\u001b[0m, in \u001b[0;36mTD3.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Optimize the critics\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 188\u001b[0m \u001b[43mcritic_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Delayed policy updates\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[64, 64]))\n",
    "model = DDPG(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1,)\n",
    "model.learn(50000, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9acec3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>1208.78</td>\n",
       "      <td>447.0</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>827.89</td>\n",
       "      <td>18</td>\n",
       "      <td>727.91</td>\n",
       "      <td>380.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>222</td>\n",
       "      <td>1645.40</td>\n",
       "      <td>819.4</td>\n",
       "      <td>114</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>871.90</td>\n",
       "      <td>19</td>\n",
       "      <td>667.90</td>\n",
       "      <td>449.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>166</td>\n",
       "      <td>1544.90</td>\n",
       "      <td>696.9</td>\n",
       "      <td>96</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>1122.30</td>\n",
       "      <td>26</td>\n",
       "      <td>736.10</td>\n",
       "      <td>425.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>244</td>\n",
       "      <td>1157.20</td>\n",
       "      <td>819.2</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>761.45</td>\n",
       "      <td>19</td>\n",
       "      <td>307.15</td>\n",
       "      <td>194.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0      45    94      1208.78        447.0               43   \n",
       "1                  0      77   222      1645.40        819.4              114   \n",
       "2                  0      72   166      1544.90        696.9               96   \n",
       "3                  0      70   244      1157.20        819.2               92   \n",
       "\n",
       "                 buy  sell    price  sale  bprofit  sprofit  \n",
       "current_bid_idx                                              \n",
       "0                 18    18   827.89    18   727.91   380.89  \n",
       "1                 19    18   871.90    19   667.90   449.00  \n",
       "2                 26    25  1122.30    26   736.10   425.40  \n",
       "3                 19    18   761.45    19   307.15   194.35  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.head(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8a34e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd</th>\n",
       "      <th>period</th>\n",
       "      <th>step</th>\n",
       "      <th>current_bid</th>\n",
       "      <th>current_ask</th>\n",
       "      <th>current_ask_idx</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>price</th>\n",
       "      <th>sale</th>\n",
       "      <th>bprofit</th>\n",
       "      <th>sprofit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_bid_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10440</td>\n",
       "      <td>114</td>\n",
       "      <td>1423.45</td>\n",
       "      <td>516.5</td>\n",
       "      <td>61</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>876.75</td>\n",
       "      <td>18</td>\n",
       "      <td>679.05</td>\n",
       "      <td>468.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11931</td>\n",
       "      <td>163</td>\n",
       "      <td>1321.00</td>\n",
       "      <td>644.5</td>\n",
       "      <td>92</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>786.90</td>\n",
       "      <td>18</td>\n",
       "      <td>650.70</td>\n",
       "      <td>358.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13416</td>\n",
       "      <td>166</td>\n",
       "      <td>1654.50</td>\n",
       "      <td>720.9</td>\n",
       "      <td>73</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>1187.70</td>\n",
       "      <td>27</td>\n",
       "      <td>730.50</td>\n",
       "      <td>466.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13901</td>\n",
       "      <td>299</td>\n",
       "      <td>1147.90</td>\n",
       "      <td>927.3</td>\n",
       "      <td>106</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>747.10</td>\n",
       "      <td>19</td>\n",
       "      <td>321.50</td>\n",
       "      <td>144.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rnd  period  step  current_bid  current_ask  current_ask_idx  \\\n",
       "current_bid_idx                                                                 \n",
       "0                  0   10440   114      1423.45        516.5               61   \n",
       "1                  0   11931   163      1321.00        644.5               92   \n",
       "2                  0   13416   166      1654.50        720.9               73   \n",
       "3                  0   13901   299      1147.90        927.3              106   \n",
       "\n",
       "                 buy  sell    price  sale  bprofit  sprofit  \n",
       "current_bid_idx                                              \n",
       "0                 18    18   876.75    18   679.05   468.55  \n",
       "1                 18    16   786.90    18   650.70   358.70  \n",
       "2                 27    27  1187.70    27   730.50   466.80  \n",
       "3                 19    18   747.10    19   321.50   144.70  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.step_data.tail(100).groupby('current_bid_idx').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfc29c",
   "metadata": {},
   "source": [
    "### PPO - Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "daa5db6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using cpu device\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using cpu device\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Wrapping the env with a `Monitor` wrapper\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Wrapping the env with a `Monitor` wrapper\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Wrapping the env in a DummyVecEnv.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Wrapping the env in a DummyVecEnv.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---------------------------------\n",
       "| rollout/           |          |\n",
       "|    ep_len_mean     | 16       |\n",
       "|    ep_rew_mean     | 198      |\n",
       "| time/              |          |\n",
       "|    fps             | 142      |\n",
       "|    iterations      | 1        |\n",
       "|    time_elapsed    | 14       |\n",
       "|    total_timesteps | 2048     |\n",
       "---------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---------------------------------\n",
       "| rollout/           |          |\n",
       "|    ep_len_mean     | 16       |\n",
       "|    ep_rew_mean     | 198      |\n",
       "| time/              |          |\n",
       "|    fps             | 142      |\n",
       "|    iterations      | 1        |\n",
       "|    time_elapsed    | 14       |\n",
       "|    total_timesteps | 2048     |\n",
       "---------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m policy_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(net_arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(pi\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m], qf\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m]))\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:281\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime/total_timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdump(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps)\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:272\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Optimization step\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 272\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    274\u001b[0m th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
    "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
    "env = TradingEnv(db, nsteps)\n",
    "policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[64, 64]))\n",
    "model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(50000, progress_bar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbafb0",
   "metadata": {},
   "source": [
    "### A2C - Advantage Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc92acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A2C model\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "a2c_model = A2C(MlpPolicy, env, verbose=0)\n",
    "\n",
    "# Train the A2C agent for 10000 steps\n",
    "a2c_model.learn(total_timesteps=training_step, progress_bar = True)\n",
    "\n",
    "# Evaluate the trained A2C agent\n",
    "mean_reward_a2c, std_reward_a2c = evaluate_policy(a2c_model, env, n_eval_episodes=eval_steps)\n",
    "print(f\"A2C mean_reward: {mean_reward_a2c:.2f} +/- {std_reward_a2c:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e53392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
