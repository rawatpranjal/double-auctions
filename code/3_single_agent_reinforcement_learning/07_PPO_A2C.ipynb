{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawatpranjal/double-auctions/blob/main/code/3_deep_reinforcement_learning/07_PPO_A2C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6ce0ea75",
      "metadata": {
        "id": "6ce0ea75",
        "outputId": "344788ac-d9a7-43a2-d230-15dd3df9de47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/double-auctions/code/3_deep_reinforcement_learning\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "%cd /content/double-auctions/code/3_deep_reinforcement_learning\n",
        "from functions import *\n",
        "from itertools import count\n",
        "buyer_strategies = ['Honest', 'Random']\n",
        "seller_strategies = ['Random', 'Random', 'Random', 'Random', 'Random', 'Random']\n",
        "nbuyers, nsellers = len(buyer_strategies), len(seller_strategies)\n",
        "nrounds, nperiods, ntokens, nsteps, gametype, nbuyers, nsellers = 1, 100, 4, 6, '1234', len(buyer_strategies), len(seller_strategies)\n",
        "R1, R2, R3, R4 = gametype_to_ran(gametype)\n",
        "game_metadata = [nrounds, nperiods, ntokens, nbuyers, nsellers, nsteps, R1, R2, R3, R4]\n",
        "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
        "rnd = 0\n",
        "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
        "period = 0\n",
        "num_states = nsteps\n",
        "min_frac = 0.01\n",
        "max_frac = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "87aeeb4c",
      "metadata": {
        "id": "87aeeb4c"
      },
      "outputs": [],
      "source": [
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, db, nsteps, render_mode = None):\n",
        "        self.rnd = 0\n",
        "        self.period = -1\n",
        "        self.db = db\n",
        "        self.action_space = spaces.Box(0,1,(1,),dtype=np.float)\n",
        "        self.observation_space = spaces.Box(0,nsteps,(1,),dtype=np.float)\n",
        "\n",
        "    def reset(self,seed=None):\n",
        "        self.db.reset_period(self.rnd)\n",
        "        self.timestep = 0\n",
        "        self.period += 1\n",
        "        observation = np.array([0])\n",
        "        return observation, None\n",
        "\n",
        "    def step(self, action, seed=None, options=None):\n",
        "        [buyer.next_token() for buyer in self.db.buyers]\n",
        "        [seller.next_token() for seller in self.db.sellers]\n",
        "        bid_frac = action.item()\n",
        "        # convert action to bid\n",
        "        self.db.buyers[0].next_token()\n",
        "        min_bid = self.db.buyers[0].value * min_frac\n",
        "        max_bid = self.db.buyers[0].value * max_frac\n",
        "        bid = np.round(max_bid * bid_frac + (1 - bid_frac) * min_bid, 2)\n",
        "\n",
        "        # simulate market\n",
        "        bids = [buyer.ask(self.db) for buyer in self.db.buyers]\n",
        "        bids[0] = bid\n",
        "        asks = [seller.ask(self.db) for seller in self.db.sellers]\n",
        "        current_ask, current_ask_idx, current_bid, current_bid_idx = current_bid_ask(bids, asks)\n",
        "        sale, price, bprofit, sprofit, buy, sell = buy_sell(self.db, current_bid, current_bid_idx, current_ask, current_ask_idx)\n",
        "        step_data = [self.rnd, self.period, self.timestep, bids, asks, current_bid, current_bid_idx, current_ask, current_ask_idx, buy, sell, price, sale, bprofit, sprofit]\n",
        "        self.db.add_step(step_data)\n",
        "\n",
        "        # compute reward, new state\n",
        "        reward = np.array([0])\n",
        "        if sale == 1 and current_bid_idx == 0:\n",
        "            reward = np.array([bprofit])\n",
        "        observation = np.array([self.timestep + 1])\n",
        "\n",
        "        # check termination\n",
        "        self.timestep += 1\n",
        "        if self.timestep == nsteps - 1:\n",
        "            terminated = True\n",
        "            self.timestep = 0\n",
        "        else:\n",
        "            terminated = False\n",
        "        return observation, reward, terminated, {}, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d7618c",
      "metadata": {
        "id": "56d7618c"
      },
      "outputs": [],
      "source": [
        "env = TradingEnv(db, nsteps)\n",
        "rnd = 0\n",
        "observation, info = env.reset()\n",
        "for period in count():\n",
        "    for timestep in count():\n",
        "        action = env.action_space.sample()\n",
        "        observation, reward, done, info, _ = env.step(action)\n",
        "        print(f\"Rnd: {rnd}, Period: {period}, New State: {observation}, Action:{np.round(action,1)}, Reward: {np.round(reward,1)}, Period End: {done}\")\n",
        "        if done:\n",
        "            # If the episode is done, reset the environment\n",
        "            print('done')\n",
        "            observation, info = env.reset()\n",
        "            timestep += 1\n",
        "            break\n",
        "    if period == nperiods:\n",
        "        break\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55dfc29c",
      "metadata": {
        "id": "55dfc29c"
      },
      "source": [
        "### PPO + A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ef7b34a2",
      "metadata": {
        "scrolled": true,
        "id": "ef7b34a2",
        "outputId": "57abb6ca-d123-4d02-943d-e04e89061108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "a6343aaa9e5c4d64aaac45b3bebfc3d9",
            "d415e857d6af4be3801595e93beec2de"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ce6f1a6f1a6d>:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.action_space = spaces.Box(0,1,(1,),dtype=np.float)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6343aaa9e5c4d64aaac45b3bebfc3d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Policy mean_reward: 0.00 +/- 0.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO mean_reward: 86.20 +/- 2.74\n",
            "A2C mean_reward: 75.35 +/- 2.42\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO, A2C\n",
        "from stable_baselines3.ppo.policies import MlpPolicy\n",
        "from stable_baselines3.common.base_class import BaseAlgorithm\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Define your environment and parameters (replace with your actual environment setup)\n",
        "rnd = 0\n",
        "period = 0\n",
        "num_states = nsteps\n",
        "min_frac = 0.01\n",
        "max_frac = 1.0\n",
        "db = Database(game_metadata, buyer_strategies, seller_strategies)\n",
        "db.reset_round(rnd, ntokens, nbuyers, nsellers, R1, R2, R3, R4)\n",
        "env = TradingEnv(db, nsteps)\n",
        "eval_steps = 100\n",
        "training_step = 10000\n",
        "\n",
        "# Create PPO model\n",
        "from stable_baselines3.ppo.policies import MlpPolicy\n",
        "random_model = A2C(MlpPolicy, env, verbose=0)\n",
        "\n",
        "# Evaluate the random policy agent\n",
        "mean_reward_random, std_reward_random = evaluate_policy(random_model, env, n_eval_episodes=eval_steps)\n",
        "print(f\"Random Policy mean_reward: {mean_reward_random:.2f} +/- {std_reward_random:.2f}\")\n",
        "\n",
        "# Create PPO model\n",
        "from stable_baselines3.ppo.policies import MlpPolicy\n",
        "ppo_model = PPO(MlpPolicy, env, verbose=0, device=\"cuda\")\n",
        "\n",
        "# Train the PPO agent for 10000 steps\n",
        "ppo_model.learn(total_timesteps=training_step, progress_bar = True)\n",
        "\n",
        "# Evaluate the trained PPO agent\n",
        "mean_reward_ppo, std_reward_ppo = evaluate_policy(ppo_model, env, n_eval_episodes=eval_steps)\n",
        "print(f\"PPO mean_reward: {mean_reward_ppo:.2f} +/- {std_reward_ppo:.2f}\")\n",
        "\n",
        "# Create A2C model\n",
        "from stable_baselines3.ppo.policies import MlpPolicy\n",
        "a2c_model = A2C(MlpPolicy, env, verbose=0, device=\"cuda\")\n",
        "\n",
        "# Train the A2C agent for 10000 steps\n",
        "a2c_model.learn(total_timesteps=training_step)\n",
        "\n",
        "# Evaluate the trained A2C agent\n",
        "mean_reward_a2c, std_reward_a2c = evaluate_policy(a2c_model, env, n_eval_episodes=eval_steps)\n",
        "print(f\"A2C mean_reward: {mean_reward_a2c:.2f} +/- {std_reward_a2c:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b4514e",
      "metadata": {
        "id": "01b4514e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6343aaa9e5c4d64aaac45b3bebfc3d9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d415e857d6af4be3801595e93beec2de",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10,234/10,000 \u001b[0m [ \u001b[33m0:01:16\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m127 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">10,234/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:01:16</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">127 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "d415e857d6af4be3801595e93beec2de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}